# GLM-Xiaozhi å°æ™ºAIè¯­éŸ³åŠ©æ‰‹ - æ™ºè°±AIé›†æˆç‰ˆ

<div align="center">

![Xiaozhi Logo](https://img.shields.io/badge/Xiaozhi-GLM-blue)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.8%2B-green)](https://www.python.org/)
[![GLM](https://img.shields.io/badge/GLM-4.5-red)](https://open.bigmodel.cn/)
[![Stars](https://img.shields.io/github/stars/YOUR_USERNAME/xiaozhi-esp32-server-glm?style=social)](https://github.com/YOUR_USERNAME/xiaozhi-esp32-server-glm)

> ğŸ™ï¸ **æ„å»ºä½ è‡ªå·±çš„AIè¯­éŸ³åŠ©æ‰‹ï¼åŸºäºESP32ç¡¬ä»¶ä¸æ™ºè°±AIå¤§æ¨¡å‹çš„å¼€æºæ™ºèƒ½è¯­éŸ³åŠ©æ‰‹**
> 
> **Build your own AI voice assistant! Open-source intelligent voice assistant powered by ESP32 hardware and Zhipu AI models**
> 
> *æœ¬é¡¹ç›®æ˜¯å¯¹[@78](https://github.com/78)çš„å¼€æºé¡¹ç›®[xiaozhi-esp32-server](https://github.com/xinnan-tech/xiaozhi-esp32-server)çš„é‡å¤§åŠŸèƒ½å¢å¼º*
>
> *This project is a major enhancement of [@78](https://github.com/78)'s open-source [xiaozhi-esp32-server](https://github.com/xinnan-tech/xiaozhi-esp32-server)*

</div>



## Project Overview / æ¦‚è¿°

`GLM-Xiaozhi` æ˜¯ä¸€ä¸ªå¼€æºã€å¯è‡ªæ‰˜ç®¡çš„åç«¯æœåŠ¡ï¼Œæ—¨åœ¨è®©å¼€å‘è€…å’ŒæŠ€æœ¯çˆ±å¥½è€…èƒ½å¤Ÿå®Œå…¨æŒæ§è‡ªå·±çš„AIè¯­éŸ³åŠ©æ‰‹ã€‚é€šè¿‡æ›¿æ¢å¹¿å—æ¬¢è¿çš„[å°æ™ºAIè¯­éŸ³åŠ©æ‰‹](https://github.com/xinnan-tech/xiaozhi-esp32)çš„åŸç‰ˆåç«¯ï¼Œæœ¬é¡¹ç›®é›†æˆäº†**æ™ºè°±AIï¼ˆGLMï¼‰** çš„å…¨å¥—æ¨¡å‹æœåŠ¡ï¼Œä¸ºå¼ºå¤§çš„å¯¹è¯å¼AIã€å®æ—¶è¯­éŸ³äº¤äº’ä»¥åŠåˆ›æ–°çš„**AutoGLM**è®¾å¤‡è‡ªåŠ¨åŒ–ä»£ç†åŠŸèƒ½æä¾›äº†åšå®çš„åŸºç¡€ã€‚

`GLM-Xiaozhi` is an open-source, self-hostable backend service that allows developers and tech enthusiasts to take full control of their AI voice assistant. By reconstructing the original backend of the popular [Xiaozhi AI Voice Assistant](https://github.com/xinnan-tech/xiaozhi-esp32), this project integrates [**Zhipu AI (GLM)**'s](https://bigmodel.cn/) large-language models that provide a solid foundation for powerful conversational AI, real-time voice interaction, and innovative **AutoGLM** device automation capabilities.


## æ ¸å¿ƒç‰¹æ€§
- å®Œå…¨ç§æœ‰åŒ–: æ‰€æœ‰æœåŠ¡å‡éƒ¨ç½²åœ¨æ‚¨è‡ªå·±çš„æœåŠ¡å™¨ä¸Šï¼Œå½»åº•æ‘†è„±å¯¹å¤–éƒ¨æœåŠ¡çš„ä¾èµ–ï¼Œç¡®ä¿æ•°æ®éšç§å’Œå®‰å…¨ã€‚
- æ™ºè°±AIå…¨å®¶æ¡¶: æ— ç¼é›†æˆæ™ºè°±AIçš„æ——èˆ°æ¨¡å‹ï¼ŒåŒ…æ‹¬ï¼š
    - è¯­è¨€æ¨¡å‹: GLM-4.5ç³»åˆ—ï¼Œæä¾›å¼ºå¤§çš„å¯¹è¯ç†è§£å’Œé€»è¾‘æ¨ç†èƒ½åŠ›ã€‚
    - è¯­éŸ³è¯†åˆ« (ASR): glm-asrï¼Œä¸“ä¸ºè¯­éŸ³è¯†åˆ«ä¼˜åŒ–ï¼Œå‡†ç¡®é«˜æ•ˆã€‚
    - è¯­éŸ³åˆæˆ (TTS): cogtts æˆ– glm-4-voiceï¼Œæä¾›è‡ªç„¶æµç•…çš„è¯­éŸ³è¾“å‡ºã€‚
    - è§†è§‰æ¨¡å‹ (VLLM): glm-4v-flash æˆ– glm-4.5vï¼Œèµ‹äºˆå°æ™ºçœ‹æ‡‚ä¸–ç•Œçš„èƒ½åŠ›ã€‚
    - AutoGLM æ™ºèƒ½æ§åˆ¶: é€šè¿‡MCPåè®®ä¸AutoGLMä»£ç†é€šä¿¡ï¼Œå®ç°å¯¹æ‰‹æœºã€ç”µè„‘ç­‰è®¾å¤‡çš„è‡ªåŠ¨åŒ–æ§åˆ¶ï¼Œä¾‹å¦‚â€œå¸®æˆ‘æ‰“å¼€éŸ³ä¹Appå¹¶æ’­æ”¾å‘¨æ°ä¼¦çš„æ­Œâ€ã€‚
- æ¨¡å—åŒ–ä¸é«˜æ‰©å±•æ€§: é¡¹ç›®é‡‡ç”¨Provideræ¨¡å¼è®¾è®¡ï¼Œæ— è®ºæ˜¯æ›´æ¢æ¨¡å‹è¿˜æ˜¯å¢åŠ æ–°åŠŸèƒ½ï¼Œéƒ½å˜å¾—å¼‚å¸¸ç®€å•ã€‚
- è½»é‡åŒ–éƒ¨ç½²: æ— éœ€å¤æ‚çš„Dockerå®¹å™¨ï¼Œç›´æ¥é€šè¿‡æºç è¿è¡Œï¼Œæ–¹ä¾¿å¼€å‘è€…è¿›è¡Œè°ƒè¯•å’Œä¸ªæ€§åŒ–å®šåˆ¶ã€‚


| Feature / ç‰¹æ€§ | Description / æè¿° |
|---------------|-------------------|
| **ğŸ”’ Self-hosted & Controllable / è‡ªæ‰˜ç®¡ä¸å¯æ§** | Run the entire backend on your own server with complete data control / åœ¨æ‚¨è‡ªå·±çš„æœåŠ¡å™¨ä¸Šè¿è¡Œï¼Œå®Œå…¨æŒæ§æ•°æ® |
| **ğŸ¤– Zhipu AI Powered / æ™ºè°±AIå¼ºåŠ›é©±åŠ¨** | Full integration with GLM-4.5 series, ASR, TTS, and Vision models / å…¨é¢é›†æˆGLM-4.5ç³»åˆ—ã€è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³åˆæˆå’Œè§†è§‰æ¨¡å‹ |
| **ğŸ¯ AutoGLM Agent Control / AutoGLMæ™ºèƒ½ä»£ç†æ§åˆ¶** | Transform your assistant into a powerful automation agent via MCP protocol / é€šè¿‡MCPåè®®å°†åŠ©æ‰‹è½¬å˜ä¸ºå¼ºå¤§çš„è‡ªåŠ¨åŒ–ä»£ç† |
| **ğŸ“¦ Modular Architecture / æ¨¡å—åŒ–æ¶æ„** | Clean Provider pattern for easy model switching and feature extension / ç®€æ´çš„Provideræ¶æ„ï¼Œä¾¿äºæ¨¡å‹åˆ‡æ¢å’ŒåŠŸèƒ½æ‰©å±• |
| **ğŸš€ Lightweight Deployment / è½»é‡åŒ–éƒ¨ç½²** | Direct source deployment without Docker complexity / æ— éœ€Dockerï¼Œç›´æ¥æºç éƒ¨ç½² |


## System Architecture / ç³»ç»Ÿæ¶æ„

### Overall Architecture / æ•´ä½“æ¶æ„

```mermaid
graph TB
    subgraph "Hardware Layer / ç¡¬ä»¶å±‚"
        ESP32[ESP32 Device<br/>éº¦å…‹é£ + æ‰¬å£°å™¨<br/>Microphone + Speaker]
    end

    subgraph "Server Layer / æœåŠ¡å™¨å±‚ (GLM-Xiaozhi)"
        WS[WebSocket Server<br/>å®æ—¶éŸ³é¢‘æµå¤„ç†<br/>Real-time Audio Stream]
        HTTP[HTTP Server<br/>è§†è§‰åˆ†æä¸OTA<br/>Vision & OTA API]
        Core[Core Logic<br/>VAD + éŸ³é¢‘ç¼–è§£ç <br/>VAD + Audio Codec]
        Provider[Model Providers<br/>ASR, LLM, TTS, VLLM<br/>æ¨¡å‹æä¾›è€…]
        MCP_Client[AutoGLM MCP Client<br/>è®¾å¤‡æ§åˆ¶å®¢æˆ·ç«¯]
    end

    subgraph "Cloud Services / äº‘æœåŠ¡"
        ZhipuAI[Zhipu AI API Gateway<br/>æ™ºè°±AIç½‘å…³]
        AutoGLM_Server[AutoGLM Agent Server<br/>AutoGLMä»£ç†æœåŠ¡å™¨]
        subgraph "Models / æ¨¡å‹"
            GLM[GLM-4.5 Series<br/>å¯¹è¯æ¨¡å‹]
            ASR[GLM-ASR<br/>è¯­éŸ³è¯†åˆ«]
            TTS[CogTTS/GLM-4-Voice<br/>è¯­éŸ³åˆæˆ]
            VISION[GLM-4V<br/>è§†è§‰ç†è§£]
        end
    end

    ESP32 <-->|WebSocket| WS
    WS --> Core
    Core --> Provider
    Provider -->|HTTPS API| ZhipuAI
    Provider -->|Function Call| MCP_Client
    MCP_Client -->|HTTP| AutoGLM_Server
    HTTP <-->|HTTP| ESP32
    ZhipuAI --> GLM
    ZhipuAI --> ASR
    ZhipuAI --> TTS
    ZhipuAI --> VISION
```

### Core Workflow / æ ¸å¿ƒå·¥ä½œæµç¨‹

```mermaid
graph TB
    participant User as User/ç”¨æˆ·
    participant ESP32 as ESP32 Device
    participant Server as GLM-Xiaozhi Server
    participant AI as Zhipu AI API

    User->>ESP32: Voice Input / è¯­éŸ³è¾“å…¥
    ESP32->>Server: Audio Stream (WebSocket)
    Server->>Server: 1. VAD Detection / é™éŸ³æ£€æµ‹
    Server->>AI: 2. ASR (Speechâ†’Text) / è¯­éŸ³è¯†åˆ«
    AI-->>Server: Text Result / æ–‡æœ¬ç»“æœ
    Server->>AI: 3. LLM Processing / å¤§æ¨¡å‹å¤„ç†
    AI-->>Server: AI Response / AIå“åº”
    Server->>AI: 4. TTS (Textâ†’Speech) / è¯­éŸ³åˆæˆ
    AI-->>Server: Audio Data / éŸ³é¢‘æ•°æ®
    Server-->>ESP32: Audio Stream
    ESP32-->>User: Voice Output / è¯­éŸ³è¾“å‡º
```


## AutoGLM Integration / AutoGLMé›†æˆ

**AutoGLM** transforms Xiaozhi from a conversationalist to an **actor**, leveraging Zhipu GLM's powerful **Function Calling** capabilities to execute tasks on connected devices.

**AutoGLM** å°†å°æ™ºä»ä¸€ä¸ªå¯¹è¯è€…æå‡ä¸ºä¸€ä¸ª**è¡ŒåŠ¨è€…**ï¼Œåˆ©ç”¨æ™ºè°±GLMå¼ºå¤§çš„**å‡½æ•°è°ƒç”¨**èƒ½åŠ›åœ¨å…³è”è®¾å¤‡ä¸Šæ‰§è¡Œä»»åŠ¡ã€‚

### Working Principle / å·¥ä½œåŸç†

```mermaid
graph TD
    A[Voice Command<br/>è¯­éŸ³æŒ‡ä»¤<br/>"æ‰“å¼€éŸ³ä¹Appæ’­æ”¾çˆµå£«ä¹"] --> B{Intent Recognition<br/>æ„å›¾è¯†åˆ«<br/>Function Calling}
    B -->|Detected Control Intent<br/>è¯†åˆ«æ§åˆ¶æ„å›¾| C[Call autoglm_control<br/>è°ƒç”¨æ§åˆ¶å‡½æ•°]
    C -->|Task Description<br/>ä»»åŠ¡æè¿°| D[MCP Client<br/>MCPå®¢æˆ·ç«¯]
    D -->|HTTP POST| E[AutoGLM Server<br/>AutoGLMæœåŠ¡å™¨]
    E --> F[Execute Automation<br/>æ‰§è¡Œè‡ªåŠ¨åŒ–<br/>(adb/appium)]
    F --> G[Return Status<br/>è¿”å›çŠ¶æ€]
    G --> H[Generate Response<br/>ç”Ÿæˆå“åº”]
    H --> I[TTS & Playback<br/>è¯­éŸ³åˆæˆæ’­æ”¾]
```


### Core Control File / æ ¸å¿ƒæ§åˆ¶æ–‡ä»¶

**Path / è·¯å¾„**: `plugins_func/functions/autoglm_control.py`

```python
@register_function
async def autoglm_control(task_description: str, action: str = "start_task"):
    """
    Control devices through AutoGLM
    é€šè¿‡AutoGLMæ§åˆ¶è®¾å¤‡
    
    Args:
        task_description: Natural language task description
        action: Control action (start_task/get_status/stop_task)
    """
    # Function registration exposes this tool to LLM
    # API communication via aiohttp to AutoGLM server
    # Response generation based on task results
```

### Example Commands / ç¤ºä¾‹å‘½ä»¤

| Command Type / å‘½ä»¤ç±»å‹ | Examples / ç¤ºä¾‹ |
|------------------------|----------------|
| **Music Control / éŸ³ä¹æ§åˆ¶** | "æ‰“å¼€ç½‘æ˜“äº‘éŸ³ä¹æ’­æ”¾å‘¨æ°ä¼¦" / "Open Spotify and play jazz" |
| **Messaging / æ¶ˆæ¯** | "æ‰“å¼€å¾®ä¿¡å‘é€æ¶ˆæ¯" / "Open WeChat and send a message" |
| **Calendar / æ—¥ç¨‹** | "æŸ¥çœ‹ä»Šå¤©çš„æ—¥ç¨‹å®‰æ’" / "Check today's schedule" |
| **System / ç³»ç»Ÿ** | "è®¾ç½®æ˜å¤©8ç‚¹çš„é—¹é’Ÿ" / "Set an alarm for 8 AM tomorrow" |



## Model Selection Guide / æ¨¡å‹é€‰æ‹©

Choose the optimal model configuration based on your requirements:

### Language Models (LLM) / è¯­è¨€æ¨¡å‹

| Model / æ¨¡å‹  | Best For / é€‚ç”¨åœºæ™¯ |
|-------------|-------------|-------------------|------------|-------------------|
| **glm-4-flash** |  Quick responses, daily Q&A / å¿«é€Ÿå“åº”ï¼Œæ—¥å¸¸é—®ç­” |
| **glm-4.5-flash** | | Fast interactions / å¿«é€Ÿäº¤äº’ |
| **glm-4.5-air**  | **Balanced choice / å¹³è¡¡ä¹‹é€‰** âœ… |
| **glm-4.5-airx**  | Complex tasks / å¤æ‚ä»»åŠ¡ |
| **glm-4.5-x** | âš¡âš¡ | â­â­â­â­â­ | ğŸ’°ğŸ’°ğŸ’°ğŸ’° | Maximum capability / æœ€å¼ºèƒ½åŠ› |

### Vision Models (VLLM) / è§†è§‰æ¨¡å‹

| Model / æ¨¡å‹ | Response Time / å“åº”æ—¶é—´ | Capability / èƒ½åŠ› | Recommendation / æ¨èåº¦ |
|-------------|------------------------|------------------|----------------------|
| **glm-4v-flash** | ~3.2s | Basic vision / åŸºç¡€è§†è§‰ | â˜…â˜…â˜…â˜…â˜… |
| **glm-4.1v-thinking-flash** | ~6.8s | Reasoning / æ¨ç†åˆ†æ | â˜…â˜…â˜…â˜…â˜† |
| **glm-4.5v** | ~6.9s | Advanced analysis / é«˜çº§åˆ†æ | â˜…â˜…â˜…â˜…â˜† |

### Audio Models / éŸ³é¢‘æ¨¡å‹

| Type / ç±»å‹ | Model / æ¨¡å‹ | Cost / æˆæœ¬ | Quality / è´¨é‡ | Privacy / éšç§ | Recommendation / æ¨è |
|------------|-------------|------------|---------------|---------------|-------------------|
| **ASR** | GLMASR (API) | Pay-per-use / æŒ‰é‡ | â˜…â˜…â˜…â˜…â˜… | Cloud / äº‘ç«¯ | â˜…â˜…â˜…â˜…â˜… |
| **ASR** | FunASR (Local) | Free / å…è´¹ | â˜…â˜…â˜…â˜…â˜† | Local / æœ¬åœ° | â˜…â˜…â˜…â˜…â˜† |
| **TTS** | CogTTS | Pay-per-use / æŒ‰é‡ | â˜…â˜…â˜…â˜…â˜… | Cloud / äº‘ç«¯ | â˜…â˜…â˜…â˜…â˜… |
| **TTS** | EdgeTTS | Free / å…è´¹ | â˜…â˜…â˜…â˜†â˜† | Microsoft | â˜…â˜…â˜…â˜†â˜† |


## Performance Benchmarks / æ€§èƒ½æµ‹è¯•

*All tests conducted on 2-core 8GB cloud server / æ‰€æœ‰æµ‹è¯•åœ¨2æ ¸8GBäº‘æœåŠ¡å™¨ä¸Šè¿›è¡Œ*

### LLM Performance / è¯­è¨€æ¨¡å‹æ€§èƒ½

**Test Query / æµ‹è¯•è¯­å¥**: "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"

| Model / æ¨¡å‹ | Total Time / æ€»è€—æ—¶ | First Token / é¦–Token | Success Rate / æˆåŠŸç‡ | Status / çŠ¶æ€ |
|-------------|-------------------|---------------------|---------------------|--------------|
| **GLM-45-AirX** | **1.682s** | 1.297s | 100% (3/3) | âœ… Optimal |
| **GLM-45-Air** | 1.856s | 1.394s | 100% (3/3) | âœ… Excellent |
| **ChatGLMLLM** | 2.035s | **0.739s** | 100% (3/3) | âœ… Fast First |
| **GLM-4-Plus** | 2.134s | **0.585s** | 100% (3/3) | âœ… Premium |
| **GLM-45-X** | 2.544s | 2.636s | 100% (3/3) | âœ… Normal |
| **GLM-4** | 2.679s | 1.566s | 100% (3/3) | âœ… Normal |
| **GLM-45** | 2.917s | 2.374s | 100% (3/3) | âœ… Normal |
| **GLM-45-Flash** | 5.418s | 4.404s | 67% (2/3) | âš ï¸ Unstable |

### Vision Model Performance / è§†è§‰æ¨¡å‹æ€§èƒ½

| Model / æ¨¡å‹ | Response Time / å“åº”æ—¶é—´ | Stability / ç¨³å®šæ€§ | Recommendation / æ¨è |
|-------------|------------------------|-------------------|-------------------|
| **ChatGLMVLLM (glm-4v-flash)** | **3.221s** | 0.483 | â­â­â­â­â­ |
| **GLM-41V-Thinking-Flash** | 6.820s | 0.523 | â­â­â­â­ |
| **GLM-45V** | 6.923s | 0.343 | â­â­â­ |

### ASR Performance / è¯­éŸ³è¯†åˆ«æ€§èƒ½

| Model / æ¨¡å‹ | Average Time / å¹³å‡è€—æ—¶ | Type / ç±»å‹ | Recommendation / æ¨è |
|-------------|----------------------|------------|-------------------|
| **SherpaASR** | **2.867s** | Local / æœ¬åœ° | â­â­â­â­â­ |
| **FunASR** | 3.058s | Local / æœ¬åœ° | â­â­â­â­ |
| **GLMASR** | 4.374s | API / äº‘ç«¯ | â­â­â­ |



## Quick Start / å¿«é€Ÿå…¥é—¨

### System Requirements / ç³»ç»Ÿè¦æ±‚

| Component / ç»„ä»¶ | Minimum / æœ€ä½é…ç½® | Recommended / æ¨èé…ç½® |
|-----------------|-------------------|----------------------|
| **CPU** | 2 cores | 4+ cores |
| **RAM** | 4GB (API only) | 8GB+ (with local models) |
| **Storage** | 10GB | 20GB+ |
| **OS** | Linux (Ubuntu 20.04+, CentOS 7+) | Ubuntu 22.04 LTS |
| **Python** | 3.8+ | 3.10+ |
| **Network** | Public IP, ports 8000, 8003 | Dedicated server |

### Installation Steps / å®‰è£…æ­¥éª¤

#### 1ï¸âƒ£ Get Zhipu AI API Key / è·å–æ™ºè°±AIå¯†é’¥

Visit [Zhipu AI Platform](https://open.bigmodel.cn) to register and create your API key.

è®¿é—®[æ™ºè°±å¼€æ”¾å¹³å°](https://open.bigmodel.cn)æ³¨å†Œå¹¶åˆ›å»ºAPIå¯†é’¥ã€‚

#### 2ï¸âƒ£ Clone Repository / å…‹éš†ä»“åº“

```bash
# Clone the repository / å…‹éš†é¡¹ç›®
git clone https://github.com/YOUR_USERNAME/GLM-Xiaozhi.git
cd GLM-Xiaozhi

# Add upstream for updates / æ·»åŠ ä¸Šæ¸¸ä»“åº“ä»¥è·å–æ›´æ–°
git remote add upstream https://github.com/78/xiaozhi-esp32-server.git
```

#### 3ï¸âƒ£ Setup Python Environment / è®¾ç½®Pythonç¯å¢ƒ

```bash
# Create virtual environment / åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Verify Python version / éªŒè¯Pythonç‰ˆæœ¬
python --version

# Install dependencies / å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

#### 4ï¸âƒ£ Configure API Keys / é…ç½®APIå¯†é’¥

Create secure configuration override / åˆ›å»ºå®‰å…¨é…ç½®è¦†ç›–:

```bash
# Create data directory / åˆ›å»ºæ•°æ®ç›®å½•
mkdir data

# Create override config / åˆ›å»ºè¦†ç›–é…ç½®
touch data/.config.yaml
```

Edit `data/.config.yaml`:

```yaml
# Zhipu AI Configuration / æ™ºè°±AIé…ç½®
LLM:
  GLM-45:
    api_key: "YOUR_ZHIPU_API_KEY"
    temperature: 0.7  # Optional / å¯é€‰
    max_tokens: 2048  # Optional / å¯é€‰
  ChatGLMLLM:
    api_key: "YOUR_ZHIPU_API_KEY"

VLLM:
  ChatGLMVLLM:
    api_key: "YOUR_ZHIPU_API_KEY"

ASR:
  GLMASR:
    api_key: "YOUR_ZHIPU_API_KEY"

TTS:
  CogTTS:
    api_key: "YOUR_ZHIPU_API_KEY"

# AutoGLM Configuration (Optional) / AutoGLMé…ç½®ï¼ˆå¯é€‰ï¼‰
autoglm:
  api_key: "YOUR_AUTOGLM_TOKEN"
  base_url: "http://your-autoglm-server:port"
```

æ¨¡å—é€‰æ‹©  selected_module

```yaml
# config.yaml
selected_module:
  llm: "ChatGLMLLM"   # LLM provider / è¯­è¨€æ¨¡å‹
  asr: "GLMASR"       # ASR provider / è¯­éŸ³è¯†åˆ«
  tts: "CogTTS"       # TTS provider / è¯­éŸ³åˆæˆ
  vllm: "ChatGLMVLLM" # Vision provider / è§†è§‰æ¨¡å‹

```




### Example Service Endpoints / æœåŠ¡æ¥å£åœ°å€*

| Service / æœåŠ¡ | URL | Description / æè¿° |
|---------------|-----|-------------------|
| **WebSocket** | `ws://101.37.205.115:8000/xiaozhi/v1/` | Real-time audio streaming / å®æ—¶éŸ³é¢‘æµ |
| **Vision API** | `http://101.37.205.115:8003/mcp/vision/explain` | Image analysis / å›¾åƒåˆ†ææ¥å£ |
| **Test Tool** | `http://101.37.205.115:8003/xiaozhi/ota/` | Service testing / æœåŠ¡æµ‹è¯•å·¥å…· |
| **OTA Config** | `https://2662r3426b.vicp.fun/xiaozhi/ota/` | OTA configuration / OTAé…ç½®æ¥å£ |


#### 5ï¸âƒ£ Start the app

ç›´æ¥è¿è¡Œ

```bash
# Direct run / ç›´æ¥è¿è¡Œ
python app.py

# Background run / åå°è¿è¡Œ
nohup python app.py > xiaozhi.log 2>&1 &

```

æœåŠ¡å™¨

```
# Using systemd (Recommended for production / ç”Ÿäº§ç¯å¢ƒæ¨è)
sudo systemctl start glm-xiaozhi.service

sudo systemctl enable glm-xiaozhi  # Auto-start on boot / å¼€æœºè‡ªå¯

# Check logs / æŸ¥çœ‹æ—¥å¿—
sudo journalctl -u glm-xiaozhi -f
```

### Logging & Debugging / æ—¥å¿—ä¸è°ƒè¯•

```bash
# Real-time logs / å®æ—¶æ—¥å¿—
tail -f xiaozhi.log

# Error filtering / é”™è¯¯è¿‡æ»¤
grep ERROR xiaozhi.log

# System monitoring / ç³»ç»Ÿç›‘æ§
htop
iotop
nethogs

# Service status / æœåŠ¡çŠ¶æ€
systemctl status glm-xiaozhi
```

## ESP32 Device Configuration / ESP32è®¾å¤‡é…ç½®

#### Method 1: Web OTA / ç½‘é¡µOTAé…ç½®

1. Access / è®¿é—®: `http://YOUR_SERVER_IP:8003/xiaozhi/ota/`
2. Enter configuration / è¾“å…¥é…ç½®:
   - WebSocket URL: `ws://YOUR_SERVER_IP:8000/xiaozhi/v1/`
   - Vision API: `http://YOUR_SERVER_IP:8003/mcp/vision/explain`
3. Save and restart device / ä¿å­˜å¹¶é‡å¯è®¾å¤‡

#### Method 2: ESP-IDF / ESP-IDFé…ç½®

```bash
# Configure / é…ç½®
idf.py menuconfig
# Navigate to Xiaozhi Configuration
# Set server addresses

# Build and flash / ç¼–è¯‘çƒ§å½•
idf.py build
idf.py flash

# Monitor / ç›‘æ§
idf.py monitor
```



## ğŸ¯ Special Features / ç‰¹è‰²åŠŸèƒ½

### ğŸ‘¨â€ğŸ« "Teacher Xiaoping" Persona / "å°å¹³è€å¸ˆ"è§’è‰²

A built-in AI assistant persona specialized in technology and education:

å†…ç½®çš„æŠ€æœ¯æ•™è‚²ä¸“å®¶AIè§’è‰²ï¼š

- **Technical Explanations / æŠ€æœ¯è§£è¯»**: "å°å¹³è€å¸ˆï¼Œè§£é‡Šä¸€ä¸‹transformeræ¶æ„"
- **Programming Help / ç¼–ç¨‹è¾…åŠ©**: "å°å¹³è€å¸ˆï¼Œå¸®æˆ‘å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•"
- **Project Consulting / é¡¹ç›®å’¨è¯¢**: "å°å¹³è€å¸ˆï¼Œæ™ºèƒ½å®¶å±…é¡¹ç›®æœ‰ä»€ä¹ˆå»ºè®®ï¼Ÿ"

Customize personas in `config.yaml`:

```yaml
prompt:
  system_prompt: |
    ä½ æ˜¯å°å¹³è€å¸ˆï¼Œä¸€ä½ç²¾é€šæ™ºè°±AIå…¨æ ˆæŠ€æœ¯çš„ä¸“å®¶...
    You are Teacher Xiaoping, an expert in Zhipu AI technologies...
```

### ğŸµ Music Control / éŸ³ä¹æ§åˆ¶

| Type / ç±»å‹ | Method / æ–¹æ³• | Example / ç¤ºä¾‹ |
|------------|--------------|---------------|
| **Local / æœ¬åœ°** | Place `.mp3` in `music/` folder | "æ’­æ”¾éŸ³ä¹" |
| **Online / åœ¨çº¿** | Stream via network | "æ’­æ”¾ç½‘ç»œéŸ³ä¹" |
| **App Control / åº”ç”¨æ§åˆ¶** | Via AutoGLM | "æ‰“å¼€Spotifyæ’­æ”¾çˆµå£«ä¹" |

### ğŸ§  Memory System / è®°å¿†ç³»ç»Ÿ

| Type / ç±»å‹ | Status / çŠ¶æ€ | Description / æè¿° |
|------------|--------------|-------------------|
| **Short-term / çŸ­æœŸ** | âœ… Active | Current conversation context / å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡ |
| **Long-term / é•¿æœŸ** | ğŸš§ Planned | User preferences via mem0ai / ç”¨æˆ·åå¥½å­˜å‚¨ |

---

## ğŸ”§ Development / å¼€å‘

### Provider Architecture / Provideræ¶æ„

```python
# Example: Custom LLM Provider / è‡ªå®šä¹‰LLMæä¾›è€…ç¤ºä¾‹
class CustomLLMProvider(BaseLLMProvider):
    """Custom LLM provider implementation"""
    
    async def response(self, prompt: str) -> str:
        """Generate response for prompt"""
        # Implementation here
        pass
    
    async def response_with_functions(
        self, 
        prompt: str, 
        functions: list
    ) -> dict:
        """Generate response with function calling"""
        # Implementation here
        pass
```

### Adding New Models / æ·»åŠ æ–°æ¨¡å‹

1. **Create Provider / åˆ›å»ºæä¾›è€…**: Implement provider class in appropriate directory
2. **Register / æ³¨å†Œ**: Add to configuration file
3. **Select / é€‰æ‹©**: Update `selected_module` in config
4. **Test / æµ‹è¯•**: Verify functionality


## Troubleshooting / æ•…éšœæ’é™¤

### Common Issues / å¸¸è§é—®é¢˜

#### WebSocket Connection Failed / WebSocketè¿æ¥å¤±è´¥

```bash
# Check firewall / æ£€æŸ¥é˜²ç«å¢™
sudo firewall-cmd --add-port=8000/tcp --permanent
sudo firewall-cmd --add-port=8003/tcp --permanent
sudo firewall-cmd --reload

# Verify server status / éªŒè¯æœåŠ¡å™¨çŠ¶æ€
netstat -antp | grep python
ps aux | grep app.py
```

#### GLM-4-Voice Issues / GLM-4-Voiceé—®é¢˜

- **Problem / é—®é¢˜**: API occasionally returns errors / APIå¶å°”è¿”å›é”™è¯¯
- **Solution / è§£å†³**: Use CogTTS as primary TTS / ä½¿ç”¨CogTTSä½œä¸ºä¸»è¦TTS

#### High Latency / é«˜å»¶è¿Ÿ

1. Switch to Flash models / åˆ‡æ¢åˆ°Flashæ¨¡å‹
2. Enable local ASR if possible / å¯ç”¨æœ¬åœ°ASR
3. Check network connectivity / æ£€æŸ¥ç½‘ç»œè¿æ¥
4. Monitor server resources / ç›‘æ§æœåŠ¡å™¨èµ„æº



## Acknowledgments / è‡´è°¢

This project stands on the shoulders of giants. Special thanks to:

æœ¬é¡¹ç›®åŸºäºå¼€æºç¤¾åŒºçš„è´¡çŒ®ï¼Œç‰¹åˆ«æ„Ÿè°¢ï¼š

- **[@78 (è™¾å“¥)](https://github.com/78)** - Original Xiaozhi creator / å°æ™ºåŸä½œè€…
- **[Zhipu AI / æ™ºè°±AI](https://www.zhipuai.cn/)** - AI model provider / AIæ¨¡å‹æä¾›æ–¹
- **Open Source Community / å¼€æºç¤¾åŒº** - All contributors / æ‰€æœ‰è´¡çŒ®è€…

### Related Resources / ç›¸å…³èµ„æº

- ğŸ“¦ [Original Project / åŸé¡¹ç›®](https://github.com/78/xiaozhi-esp32)
- ğŸ–¥ï¸ [Server Repository / æœåŠ¡å™¨ç«¯](https://github.com/78/xiaozhi-esp32-server)
- ğŸ“š [Zhipu AI Docs / æ™ºè°±AIæ–‡æ¡£](https://open.bigmodel.cn/dev/api)
- ğŸ”§ [ESP32 Documentation / ESP32æ–‡æ¡£](https://docs.espressif.com/projects/esp-idf/zh_CN/latest/esp32/)
- ğŸ› ï¸ [Hardware Tutorial / ç¡¬ä»¶æ•™ç¨‹](https://github.com/78/xiaozhi-esp32)



<div align="center">

**âš ï¸ Disclaimer / å…è´£å£°æ˜**

This project is for learning and research purposes only.  
æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ã€‚

**Made with â¤ï¸ by the Xiaozhi Community**

**ç”±å°æ™ºç¤¾åŒºç”¨â¤ï¸æ‰“é€ **

</div>
