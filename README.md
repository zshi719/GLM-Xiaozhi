# GLM-Xiaozhi å°æ™ºAIè¯­éŸ³åŠ©æ‰‹ - æ™ºè°±AIé›†æˆç‰ˆ

<div align="center">

![Xiaozhi Logo](https://img.shields.io/badge/Xiaozhi-GLM-blue)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.8%2B-green)](https://www.python.org/)
[![GLM](https://img.shields.io/badge/GLM-4.5-red)](https://open.bigmodel.cn/)
[![Stars](https://img.shields.io/github/stars/YOUR_USERNAME/xiaozhi-esp32-server-glm?style=social)](https://github.com/YOUR_USERNAME/xiaozhi-esp32-server-glm)

> ğŸ™ï¸ **Open-source intelligent voice assistant powered by ESP32 hardware and Zhipu AI models**
> 
> åŸºäºESP32ç¡¬ä»¶ä¸æ™ºè°±AIå¤§æ¨¡å‹çš„å¼€æºæ™ºèƒ½è¯­éŸ³åŠ©æ‰‹
> 
> Original project by [@78](https://github.com/78) | åŸé¡¹ç›®æ¥è‡ªè™¾å“¥çš„å¼€æºè´¡çŒ®

</div>

<<<<<<< HEAD
---

## ğŸ“Œ Table of Contents / ç›®å½•

- [Project Overview / é¡¹ç›®æ¦‚è¿°](#project-overview--é¡¹ç›®æ¦‚è¿°)
- [System Architecture / ç³»ç»Ÿæ¶æ„](#system-architecture--ç³»ç»Ÿæ¶æ„)
- [Core Features / æ ¸å¿ƒç‰¹æ€§](#core-features--æ ¸å¿ƒç‰¹æ€§)
- [Quick Start / å¿«é€Ÿå¼€å§‹](#quick-start--å¿«é€Ÿå¼€å§‹)
- [Model Selection Guide / æ¨¡å‹é€‰æ‹©æŒ‡å—](#model-selection-guide--æ¨¡å‹é€‰æ‹©æŒ‡å—)
- [Performance Benchmarks / æ€§èƒ½æµ‹è¯•](#performance-benchmarks--æ€§èƒ½æµ‹è¯•)
- [AutoGLM Integration / AutoGLMé›†æˆ](#autoglm-integration--autoglmé›†æˆ)
- [Configuration / é…ç½®](#configuration--é…ç½®)
- [Troubleshooting / æ•…éšœæ’é™¤](#troubleshooting--æ•…éšœæ’é™¤)
- [Contributing / è´¡çŒ®](#contributing--è´¡çŒ®)

---

## Project Overview / é¡¹ç›®æ¦‚è¿°

**GLM-Xiaozhi** is a comprehensive transformation of the [Xiaozhi AI Voice Assistant](https://github.com/78/xiaozhi-esp32) server backend, implementing seamless integration with Zhipu AI's full model suite. This project provides a complete private deployment solution that eliminates dependency on official servers while delivering enhanced conversational, voice, and visual capabilities.

æœ¬é¡¹ç›®æ˜¯å¯¹[å°æ™ºAIè¯­éŸ³åŠ©æ‰‹](https://github.com/78/xiaozhi-esp32)æœåŠ¡å™¨ç«¯çš„å…¨é¢æ”¹é€ ï¼Œå®ç°ä¸æ™ºè°±AIå…¨ç³»åˆ—æ¨¡å‹çš„æ— ç¼å¯¹æ¥ï¼Œæä¾›å®Œå…¨ç§æœ‰åŒ–çš„éƒ¨ç½²æ–¹æ¡ˆã€‚

### ğŸŒŸ Key Highlights / æ ¸å¿ƒäº®ç‚¹

- **ğŸ”’ Complete Privatization / å®Œå…¨ç§æœ‰åŒ–**: Deploy all services on your own server for maximum data privacy
- **ğŸ¤– Zhipu AI Full Stack / æ™ºè°±AIå…¨å®¶æ¡¶**: Integrated support for GLM-4.5 series, voice models, and vision capabilities
- **ğŸ¯ AutoGLM Control / æ™ºèƒ½æ§åˆ¶**: Device automation through MCP protocol integration
- **ğŸ“¦ Modular Architecture / æ¨¡å—åŒ–æ¶æ„**: Easy-to-extend Provider pattern design
- **ğŸš€ Lightweight Deployment / è½»é‡åŒ–éƒ¨ç½²**: Direct source code deployment without Docker dependencies

---

## System Architecture / ç³»ç»Ÿæ¶æ„

### Overall Architecture Diagram / æ•´ä½“æ¶æ„å›¾

```mermaid
graph TB
    subgraph "Hardware Layer / ç¡¬ä»¶å±‚"
        ESP32[ESP32 Device<br/>éº¦å…‹é£ + æ‰¬å£°å™¨<br/>Microphone + Speaker]
    end
    
    subgraph "Server Layer / æœåŠ¡å™¨å±‚"
        WS[WebSocket Server<br/>å®æ—¶éŸ³é¢‘æµå¤„ç†<br/>Real-time Audio Stream]
        HTTP[HTTP Server<br/>è§†è§‰åˆ†æä¸OTA<br/>Vision & OTA]
        AUDIO[Audio Processing<br/>VAD + æ ¼å¼è½¬æ¢<br/>VAD + Format Conversion]
        PROVIDER[Model Providers<br/>æ¨¡å‹æä¾›è€…æ¥å£]
        MCP[AutoGLM MCP Client<br/>è®¾å¤‡æ§åˆ¶å®¢æˆ·ç«¯]
    end
    
    subgraph "Zhipu AI Cloud / æ™ºè°±AIäº‘ç«¯"
        ZHIPU[Zhipu AI API Gateway]
        GLM[GLM-4.5 å¯¹è¯æ¨¡å‹<br/>Dialogue Model]
        ASR[GLM-ASR è¯­éŸ³è¯†åˆ«<br/>Speech Recognition]
        TTS[GLM-4-Voice è¯­éŸ³åˆæˆ<br/>Voice Synthesis]
        VISION[GLM-4V è§†è§‰ç†è§£<br/>Vision Understanding]
    end
    
    ESP32 <-->|WebSocket| WS
    WS <--> AUDIO
    AUDIO <--> PROVIDER
    PROVIDER <--> ZHIPU
    PROVIDER <--> MCP
    ZHIPU --> GLM
    ZHIPU --> ASR
    ZHIPU --> TTS
    ZHIPU --> VISION
=======
# GLM-Xiaozhi: åŸºäºæ™ºè°±AIçš„å¼€æºè¯­éŸ³åŠ©æ‰‹åç«¯

<div align="center">

![Xiaozhi Logo](https://img.shields.io/badge/Xiaozhi-GLM-blue)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.8%2B-green)](https://www.python.org/)
[![GLM](https://img.shields.io/badge/GLM-4.5-red)](https://open.bigmodel.cn/)

> ğŸ™ï¸ **æ„å»ºä½ è‡ªå·±çš„AIè¯­éŸ³åŠ©æ‰‹ï¼** è¿™æ˜¯ä¸€ä¸ªä¸ºESP32ç¡¬ä»¶è®¾è®¡çš„å¼€æºåç«¯ï¼Œç”±æ™ºè°±AIï¼ˆGLMï¼‰çš„å…ˆè¿›æ¨¡å‹å¼ºåŠ›é©±åŠ¨ã€‚
>
> *æœ¬é¡¹ç›®æ˜¯å¯¹[@78](https://github.com/78)çš„å¼€æºé¡¹ç›®[xiaozhi-esp32-server](https://github.com/xinnan-tech/xiaozhi-esp32-server)çš„é‡å¤§åŠŸèƒ½å¢å¼ºã€‚è¡·å¿ƒæ„Ÿè°¢åŸä½œè€…åŠå¼€æºç¤¾åŒºçš„è´¡çŒ®ï¼*

</div>

---
### **æœåŠ¡æ¥å£åœ°å€ (ç¤ºä¾‹)**
>>>>>>> ef0082b (docs: note that large model files are excluded and how to add them)
```
è§†è§‰åˆ†ææ¥å£: [http://101.37.205.115:8003/mcp/vision/explain](http://101.37.205.115:8003/mcp/vision/explain)
æœåŠ¡æµ‹è¯•å·¥å…·: [http://101.37.205.115:8003/xiaozhi/ota/](http://101.37.205.115:8003/xiaozhi/ota/)
OTAæ¥å£åœ°å€:  [https://2662r3426b.vicp.fun/xiaozhi/ota/](https://2662r3426b.vicp.fun/xiaozhi/ota/)
Websocketæ¥å£åœ°å€: ws://101.37.205.115:8000/xiaozhi/v1/
```
---

## 1. é¡¹ç›®æ¦‚è¿°

`GLM-Xiaozhi` æ˜¯ä¸€ä¸ªå¼€æºã€å¯è‡ªæ‰˜ç®¡çš„åç«¯æœåŠ¡ï¼Œæ—¨åœ¨è®©å¼€å‘è€…å’ŒæŠ€æœ¯çˆ±å¥½è€…èƒ½å¤Ÿå®Œå…¨æŒæ§è‡ªå·±çš„AIè¯­éŸ³åŠ©æ‰‹ã€‚é€šè¿‡æ›¿æ¢å¹¿å—æ¬¢è¿çš„[å°æ™ºAIè¯­éŸ³åŠ©æ‰‹](https://github.com/xinnan-tech/xiaozhi-esp32)çš„åŸç‰ˆåç«¯ï¼Œæœ¬é¡¹ç›®é›†æˆäº†**æ™ºè°±AIï¼ˆGLMï¼‰** çš„å…¨å¥—æ¨¡å‹æœåŠ¡ã€‚è¿™ä¸ºå¼ºå¤§çš„å¯¹è¯å¼AIã€å®æ—¶è¯­éŸ³äº¤äº’ä»¥åŠåˆ›æ–°çš„**AutoGLM**è®¾å¤‡è‡ªåŠ¨åŒ–ä»£ç†åŠŸèƒ½æä¾›äº†åšå®çš„åŸºç¡€ã€‚

`GLM-Xiaozhi` é‡‡ç”¨çº¯Pythonå’Œæ¨¡å—åŒ–æ¶æ„ï¼Œæ˜“äºéƒ¨ç½²ã€å®šåˆ¶å’Œæ‰©å±•ï¼Œæ˜¯æ‚¨æ‰“é€ ä¸‹ä¸€ä»£æ™ºèƒ½åŠ©ç†çš„ç†æƒ³èµ·ç‚¹ã€‚

<<<<<<< HEAD
### Workflow Sequence / å·¥ä½œæµç¨‹

```mermaid
sequenceDiagram
    participant User as User/ç”¨æˆ·
    participant ESP32
    participant Server as GLM-Xiaozhi
    participant ZhipuAI as Zhipu AI

    User->>ESP32: Voice Input / è¯­éŸ³è¾“å…¥
    ESP32->>Server: Audio Stream (WebSocket)
    Server->>Server: VAD Detection / é™éŸ³æ£€æµ‹
    Server->>ZhipuAI: ASR (Speech to Text)
    ZhipuAI-->>Server: Text Result / æ–‡æœ¬ç»“æœ
    Server->>ZhipuAI: LLM Processing / å¤§æ¨¡å‹å¤„ç†
    ZhipuAI-->>Server: AI Response / AIå“åº”
    Server->>ZhipuAI: TTS (Text to Speech)
    ZhipuAI-->>Server: Audio Data / éŸ³é¢‘æ•°æ®
    Server-->>ESP32: Audio Stream
    ESP32-->>User: Voice Output / è¯­éŸ³è¾“å‡º
```

---

## Core Features / æ ¸å¿ƒç‰¹æ€§

### ğŸ¤ Voice Interaction / è¯­éŸ³äº¤äº’
- **ASR (Speech Recognition / è¯­éŸ³è¯†åˆ«)**: GLM-ASR, FunASR, SherpaASR
- **TTS (Text to Speech / è¯­éŸ³åˆæˆ)**: CogTTS, GLM-4-Voice, EdgeTTS
- **VAD (Voice Activity Detection / é™éŸ³æ£€æµ‹)**: Real-time speech boundary detection
=======
### æ ¸å¿ƒç‰¹æ€§

-   **è‡ªæ‰˜ç®¡ä¸å¯æ§**: åœ¨æ‚¨è‡ªå·±çš„æœåŠ¡å™¨ä¸Šè¿è¡Œæ•´ä¸ªåç«¯ï¼Œè®©æ‚¨å®Œå…¨æŒæ¡æ•°æ®å’Œè¿è¥é€»è¾‘ã€‚
-   **æ™ºè°±AIå¼ºåŠ›é©±åŠ¨**: å…¨é¢åˆ©ç”¨æ™ºè°±AIæ——èˆ°æ¨¡å‹çš„é¡¶å°–æ€§èƒ½ï¼š
    -   **è¯­è¨€æ¨¡å‹**: `GLM-4.5`ç³»åˆ—ï¼Œæä¾›å“è¶Šçš„ç†è§£ä¸æ¨ç†èƒ½åŠ›ã€‚
    -   **è¯­éŸ³è¯†åˆ« (ASR)**: `glm-asr`ï¼Œå®ç°å¿«é€Ÿç²¾å‡†çš„è¯­éŸ³è½¬æ–‡æœ¬ã€‚
    -   **è¯­éŸ³åˆæˆ (TTS)**: `cogtts` å’Œ `glm-4-voice`ï¼Œç”Ÿæˆè‡ªç„¶æµç•…çš„äººå£°ã€‚
    -   **è§†è§‰æ¨¡å‹ (VLLM)**: `glm-4v`ç³»åˆ—ï¼Œèµ‹äºˆåŠ©æ‰‹è§†è§‰ç†è§£çš„èƒ½åŠ›ã€‚
-   **ğŸŒŸ AutoGLMæ™ºèƒ½ä»£ç†æ§åˆ¶**: ä¸€é¡¹æ°å‡ºåŠŸèƒ½ï¼Œé€šè¿‡MCPåè®®å°†æ‚¨çš„åŠ©æ‰‹è½¬å˜ä¸ºä¸€ä¸ªå¼ºå¤§çš„æ™ºèƒ½ä»£ç†ï¼Œèƒ½å¤Ÿè‡ªåŠ¨åŒ–æ‰§è¡Œæ‰‹æœºç­‰è®¾å¤‡ä¸Šçš„ä»»åŠ¡ã€‚
-   **æ¨¡å—åŒ–ä¸é«˜æ‰©å±•æ€§**: ç®€æ´çš„Provideræ¶æ„ä½¿æ›´æ¢æ¨¡å‹ã€æ·»åŠ æ–°å·¥å…·æˆ–é›†æˆè‡ªå®šä¹‰åŠŸèƒ½å˜å¾—è½»è€Œæ˜“ä¸¾ã€‚
-   **è½»é‡åŒ–éƒ¨ç½²**: æ— éœ€å¤æ‚çš„Dockerï¼Œå¯ç›´æ¥ä»æºç éƒ¨ç½²ï¼Œä¾¿äºè°ƒè¯•å’Œå¼€å‘ã€‚

---

## 2. ç³»ç»Ÿæ¶æ„ä¸æŠ€æœ¯æµç¨‹

### 2.1. æ•´ä½“ç³»ç»Ÿæ¶æ„

ç³»ç»Ÿç”±ç¡¬ä»¶å®¢æˆ·ç«¯ï¼ˆESP32ï¼‰ã€è‡ªæ‰˜ç®¡æœåŠ¡å™¨ï¼ˆ`GLM-Xiaozhi`ï¼‰å’Œæ™ºè°±AIäº‘æœåŠ¡ä¸‰å±‚ç»„æˆï¼Œå®ƒä»¬ååŒå·¥ä½œï¼Œæä¾›æ— ç¼çš„è¯­éŸ³ä½“éªŒã€‚

```mermaid
graph TB
    subgraph "ç¡¬ä»¶å±‚ (å®¢æˆ·ç«¯)"
        ESP32[ESP32 è®¾å¤‡<br/>éº¦å…‹é£ + æ‰¬å£°å™¨]
    end

    subgraph "æœåŠ¡å™¨å±‚ (GLM-Xiaozhi)"
        WS[WebSocket æœåŠ¡å™¨<br/>å¤„ç†å®æ—¶éŸ³é¢‘æµ]
        HTTP[HTTP æœåŠ¡å™¨<br/>æä¾›è§†è§‰ & OTA API]
        Core[æ ¸å¿ƒé€»è¾‘<br/>VAD, éŸ³é¢‘ç¼–è§£ç ]
        Provider[æ¨¡å‹æä¾›è€…<br/>ASR, LLM, TTS, VLLM]
        MCP_Client[AutoGLM (MCP) å®¢æˆ·ç«¯]
    end

    subgraph "äº‘æœåŠ¡"
        ZhipuAI[æ™ºè°±AI API]
        AutoGLM_Server[AutoGLM ä»£ç†æœåŠ¡å™¨]
    end

    ESP32 <-->|WebSocket (wss://)| WS
    WS --> Core
    Core --> Provider
    Provider -->|HTTPS API è°ƒç”¨| ZhipuAI
    Provider -->|å‡½æ•°è°ƒç”¨| MCP_Client
    MCP_Client -->|HTTP è¯·æ±‚| AutoGLM_Server
    HTTP <-->|HTTP è¯·æ±‚| ESP32 & æµè§ˆå™¨
```

### 2.2. æ ¸å¿ƒäº¤äº’æµç¨‹

ä»ç”¨æˆ·è¯éŸ³è¾“å…¥åˆ°AIè¯­éŸ³è¾“å‡ºï¼Œæ•°æ®æµç»ä¸€ä¸ªç²¾ç¡®å®šä¹‰çš„å¤„ç†ç®¡çº¿ã€‚

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant ESP32_Device as ESP32 è®¾å¤‡
    participant GLM_Xiaozhi_Server as GLM-Xiaozhi æœåŠ¡å™¨
    participant ZhipuAI_API as æ™ºè°±AI API

    User->>ESP32_Device: è¯´è¯ (ä¾‹å¦‚ï¼š"ä½ å¥½å°æ™º")
    ESP32_Device->>GLM_Xiaozhi_Server: å®æ—¶éŸ³é¢‘æµ (WebSocket)
    GLM_Xiaozhi_Server->>GLM_Xiaozhi_Server: **1. VAD**: æ£€æµ‹è¯­éŸ³ç»“æŸ
    GLM_Xiaozhi_Server->>ZhipuAI_API: **2. ASR**: è°ƒç”¨ `glm-asr` å°†éŸ³é¢‘è½¬ä¸ºæ–‡æœ¬
    ZhipuAI_API-->>GLM_Xiaozhi_Server: è¿”å›è½¬å½•æ–‡æœ¬ ("ä½ å¥½å°æ™º")
    GLM_Xiaozhi_Server->>ZhipuAI_API: **3. LLM**: æ„é€ æç¤ºå¹¶è°ƒç”¨ `GLM-4.5` ç³»åˆ—æ¨¡å‹
    ZhipuAI_API-->>GLM_Xiaozhi_Server: è¿”å›æµå¼æ–‡æœ¬å“åº” ("ä½ å¥½ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨ï¼Ÿ")
    GLM_Xiaozhi_Server->>ZhipuAI_API: **4. TTS**: è°ƒç”¨ `cogtts` å°†æ–‡æœ¬åˆæˆä¸ºè¯­éŸ³
    ZhipuAI_API-->>GLM_Xiaozhi_Server: è¿”å›éŸ³é¢‘æ•°æ®
    GLM_Xiaozhi_Server-->>ESP32_Device: å°†éŸ³é¢‘æµä¼ å›è®¾å¤‡æ’­æ”¾
    ESP32_Device-->>User: æ’­æ”¾åˆæˆè¯­éŸ³
```

---

## 3. ğŸŒŸ äº®ç‚¹åŠŸèƒ½: AutoGLM è‡ªåŠ¨åŒ–ä»£ç†

**AutoGLM** å°†å°æ™ºä»ä¸€ä¸ªå¯¹è¯è€…æå‡ä¸ºä¸€ä¸ª**è¡ŒåŠ¨è€…**ã€‚å®ƒåˆ©ç”¨æ™ºè°±GLMæ¨¡å‹å¼ºå¤§çš„**å‡½æ•°è°ƒç”¨ï¼ˆFunction Callingï¼‰**èƒ½åŠ›ï¼Œè§£ææ‚¨çš„æŒ‡ä»¤ï¼Œå¹¶åœ¨æ‰‹æœºç­‰å…³è”è®¾å¤‡ä¸Šæ‰§è¡Œã€‚

### 3.1. AutoGLM (MCP) å·¥ä½œåŸç†

```mermaid
graph TD
    A[ç”¨æˆ·è¯­éŸ³æŒ‡ä»¤<br/>"æ‰“å¼€éŸ³ä¹Appå¹¶æ’­æ”¾çˆµå£«ä¹"] --> B{LLM æ„å›¾è¯†åˆ«<br/>(å‡½æ•°è°ƒç”¨)};
    B -->|è¯†åˆ«åˆ° `autoglm_control` æ„å›¾| C[è°ƒç”¨ `autoglm_control` å‡½æ•°];
    C -->|ä¼ é€’å‚æ•°<br/>`task_description`: "æ‰“å¼€éŸ³ä¹Appæ’­æ”¾çˆµå£«ä¹"| D[MCP å®¢æˆ·ç«¯];
    D -->|å‘é€ HTTP POST è¯·æ±‚<br/>è‡³ AutoGLM æœåŠ¡å™¨| E[AutoGLM ä»£ç†æœåŠ¡å™¨];
    E --> F[æ‰§è¡Œç§»åŠ¨ç«¯è‡ªåŠ¨åŒ–ä»»åŠ¡<br/>(ä¾‹å¦‚: é€šè¿‡ adb, appium)];
    F --> E[è¿”å›ä»»åŠ¡çŠ¶æ€];
    E --> D[è¿”å› HTTP å“åº”];
    D --> C[å‡½æ•°è¿”å›ç»“æœ];
    C --> B{LLM};
    B -->|ç”Ÿæˆæœ€ç»ˆç”¨æˆ·ç­”å¤<br/>"å¥½çš„ï¼Œå·²ä¸ºæ‚¨æ‰“å¼€éŸ³ä¹Appå¹¶æ’­æ”¾çˆµå£«ä¹ã€‚"| G[TTS åˆæˆ & æ’­æ”¾];
```

### 3.2. æ§åˆ¶ä¸­æ¢: `plugins_func/functions/autoglm_control.py`

> **æ–‡ä»¶è·¯å¾„**: `plugins_func/functions/autoglm_control.py`

æ­¤æ–‡ä»¶æ˜¯ **AutoGLM é›†æˆçš„å¤§è„‘**ã€‚å®ƒå®šä¹‰äº†å…³é”®çš„ `autoglm_control` å‡½æ•°ï¼Œå¹¶å°†å…¶æ³¨å†Œä¸ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ä»¥ä½¿ç”¨çš„å·¥å…·ã€‚

-   **å‡½æ•°æ³¨å†Œ (`@register_function`)**: æ­¤è£…é¥°å™¨å‘LLMå…¬å¼€å‡½æ•°çš„æ¨¡å¼ï¼ˆåç§°ã€ç›®çš„ã€å‚æ•°ï¼‰ã€‚å½“LLMè§£æç”¨æˆ·è¯·æ±‚æ—¶ï¼Œå®ƒä¾¿çŸ¥é“æœ‰ä¸€ä¸ªåä¸º `autoglm_control` çš„å·¥å…·å¯ç”¨äºè®¾å¤‡æ§åˆ¶ã€‚
-   **åŠ¨ä½œåˆ†å‘**: å‡½æ•°å†…éƒ¨æ ¹æ® `action` å‚æ•°ï¼ˆå¦‚ `start_task`, `get_status`ï¼‰è·¯ç”±è¯·æ±‚ï¼Œå®ç°å¤šæ ·åŒ–æ§åˆ¶ã€‚
-   **API é€šä¿¡**: ä½¿ç”¨ `aiohttp` åº“ï¼Œå¼‚æ­¥åœ°å‘æ‚¨åœ¨ `config.yaml` ä¸­é…ç½®çš„ **AutoGLM æœåŠ¡å™¨URL** (`base_url`) å‘é€å‘½ä»¤ï¼Œå¹¶é€šè¿‡ `api_key` è¿›è¡Œå®‰å…¨è®¤è¯ã€‚
-   **å“åº”ç”Ÿæˆ**: å®ƒå¤„ç†æ¥è‡ªAutoGLMæœåŠ¡å™¨çš„å›å¤ï¼Œå‘ç”¨æˆ·æä¾›ä¿¡æ¯åé¦ˆï¼Œå¦‚â€œä»»åŠ¡å·²åˆ›å»ºï¼ŒIDä¸ºXXXâ€æˆ–â€œè·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥â€ã€‚

ç®€è€Œè¨€ä¹‹ï¼Œ`autoglm_control.py` æ˜¯å°†è‡ªç„¶è¯­è¨€çš„â€œé­”åŠ›â€è½¬åŒ–ä¸ºç²¾ç¡®è‡ªåŠ¨åŒ–åŠ¨ä½œçš„å…³é”®æ¡¥æ¢ã€‚

---

## 4. æ¨¡å‹é€‰æ‹©æŒ‡å—

æ™ºè°±AIæä¾›å¤šæ ·åŒ–çš„æ¨¡å‹ç»„åˆï¼Œæ‚¨å¯åœ¨æˆæœ¬ã€é€Ÿåº¦å’Œæ™ºèƒ½ä¹‹é—´å–å¾—å¹³è¡¡ã€‚åªéœ€åœ¨ `config.yaml` ä¸­ç¼–è¾‘ `selected_module` éƒ¨åˆ†å³å¯åˆ‡æ¢ã€‚

| æ¨¡å—ç±»å‹           | æ¨¡å‹åç§°                                   | ç‰¹æ€§ & ä½¿ç”¨åœºæ™¯                                  | ä»·æ ¼ç­‰çº§ | æ¨èåº¦ |
| :----------------- | :----------------------------------------- | :----------------------------------------------- | :------- | :----- |
| **LLM (è¯­è¨€)**     | `glm-4-flash` / `glm-4.5-flash`            | æé€Ÿï¼Œé«˜æ€§ä»·æ¯”ã€‚é€‚åˆé€šç”¨é—®ç­”å’Œå¿«é€Ÿäº¤äº’ã€‚         | ä½       | â˜…â˜…â˜…â˜…â˜…  |
|                    | `glm-4.5-air`                              | æ€§èƒ½ä¸æˆæœ¬çš„å®Œç¾å¹³è¡¡ã€‚é€‚åˆå¤æ‚å¯¹è¯ã€‚             | ä¸­       | â˜…â˜…â˜…â˜…â˜†  |
|                    | `glm-4-plus` / `glm-4.5-x`                 | æœ€å¼ºæ€§èƒ½ï¼Œç”¨äºå¤æ‚æ¨ç†ã€ç¼–ç å’Œé•¿æ–‡æœ¬ä»»åŠ¡ã€‚       | é«˜       | â˜…â˜…â˜…â˜†â˜†  |
| **VLLM (è§†è§‰)**    | `glm-4v-flash` / `glm-4.1v-thinking-flash` | å¿«é€Ÿè§†è§‰åˆ†æï¼Œé€‚åˆå®æ—¶å›¾åƒè¯†åˆ«ã€‚                 | ä½       | â˜…â˜…â˜…â˜…â˜…  |
|                    | `glm-4.5v`                                 | æ›´æ·±åº¦çš„è§†è§‰ç†è§£ï¼Œç”¨äºè¯¦ç»†çš„å›¾åƒæè¿°å’Œæ¯”è¾ƒã€‚     | ä¸­       | â˜…â˜…â˜…â˜…â˜†  |
| **ASR (è¯­éŸ³è¯†åˆ«)** | `glm-asr`                                  | æ™ºè°±å®˜æ–¹æ¨¡å‹ï¼Œä¸ºè¯­éŸ³è½¬æ–‡æœ¬ä¼˜åŒ–ï¼Œå‡†ç¡®ç‡é«˜ã€‚       | æŒ‰é‡è®¡è´¹ | â˜…â˜…â˜…â˜…â˜…  |
|                    | `FunASR` (æœ¬åœ°)                            | å…è´¹ï¼Œåœ¨æ‚¨æœåŠ¡å™¨ä¸Šè¿è¡Œä»¥ä¿æŠ¤éšç§ï¼Œä½†éœ€æ›´å¤šèµ„æºã€‚ | å…è´¹     | â˜…â˜…â˜…â˜…â˜†  |
| **TTS (è¯­éŸ³åˆæˆ)** | `cogtts`                                   | è‡ªç„¶ã€é«˜å“è´¨çš„äººå£°ï¼Œæ”¯æŒå¤šç§éŸ³è‰²ã€‚               | æŒ‰é‡è®¡è´¹ | â˜…â˜…â˜…â˜…â˜…  |
|                    | `EdgeTTS`                                  | ä¼˜ç§€çš„å…è´¹é€‰é¡¹ï¼Œä½†ä¾èµ–å¾®è½¯çš„å¤–éƒ¨æœåŠ¡ã€‚           | å…è´¹     | â˜…â˜…â˜…â˜†â˜†  |

---

## 5. æ€§èƒ½åŸºå‡†æµ‹è¯•

æ‰€æœ‰æµ‹è¯•å‡åœ¨ 2æ ¸8GB RAM çš„äº‘æœåŠ¡å™¨ä¸Šå®Œæˆï¼Œä¸ºæ‚¨æä¾›çœŸå®æ€§èƒ½å‚è€ƒã€‚

#### 5.1. LLM æ€§èƒ½

*æµ‹è¯•æç¤º: "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"*

| æ¨¡å‹åç§°                     | å¹³å‡æ€»è€—æ—¶ (s) | é¦–å­—è€—æ—¶ (s) | æˆåŠŸç‡ | çŠ¶æ€   |
| :--------------------------- | :------------- | :----------- | :----- | :----- |
| `GLM-45-AirX`                | **1.682**      | **1.297**    | 3/3    | âœ… æ­£å¸¸ |
| `GLM-45-Air`                 | 1.856          | 1.394        | 3/3    | âœ… æ­£å¸¸ |
| `ChatGLMLLM` (`glm-4-flash`) | 2.035          | 0.739        | 3/3    | âœ… æ­£å¸¸ |
| `GLM-4-Plus`                 | 2.134          | 0.585        | 3/3    | âœ… æ­£å¸¸ |
| `GLM-45-X`                   | 2.544          | 2.636        | 3/3    | âœ… æ­£å¸¸ |
| `GLM-4`                      | 2.679          | 1.566        | 3/3    | âœ… æ­£å¸¸ |
| `GLM45`                      | 2.917          | 2.374        | 3/3    | âœ… æ­£å¸¸ |
| `GLM-45-Flash`               | 5.418          | 4.404        | 2/3    | âœ… æ­£å¸¸ |

**åˆ†æ**: `Air` ç³»åˆ—æä¾›æœ€ä½³çš„æ•´ä½“å»¶è¿Ÿï¼Œè€Œ `Flash` æ¨¡å‹åˆ™æ‹¥æœ‰æœ€å¿«çš„é¦–å­—å“åº”é€Ÿåº¦ï¼Œå¸¦æ¥å³æ—¶åé¦ˆçš„ä½“éªŒã€‚

#### 5.2. VLLM (è§†è§‰) æ€§èƒ½

| æ¨¡å‹åç§°                       | å“åº”è€—æ—¶ (s) | ç¨³å®šæ€§ |
| :----------------------------- | :----------- | :----- |
| `ChatGLMVLLM` (`glm-4v-flash`) | **3.221**    | 0.483  |
| `GLM-41V-Thinking-Flash`       | 6.820        | 0.523  |
| `GLM-45V`                      | 6.923        | 0.343  |

**åˆ†æ**: å¯¹äºå®æ—¶è§†è§‰ä»»åŠ¡ï¼Œ`glm-4v-flash` åœ¨é€Ÿåº¦ä¸Šæ˜¯æ˜ç¡®çš„é¦–é€‰ã€‚

#### 5.3. ASR (è¯­éŸ³è¯†åˆ«) æ€§èƒ½

| æ¨¡å‹åç§°           | å¹³å‡è€—æ—¶ (s) |
| :----------------- | :----------- |
| `SherpaASR` (æœ¬åœ°) | **2.867**    |
| `FunASR` (æœ¬åœ°)    | 3.058        |
| `GLMASR` (API)     | 4.374        |

**åˆ†æ**: æœ¬åœ°ASRæ¨¡å‹åœ¨å±€åŸŸç½‘ä¸­å»¶è¿Ÿæ›´ä½ï¼Œè€Œ `GLMASR` API åˆ™å°†è®¡ç®—å·¥ä½œè½¬ç§»åˆ°äº‘ç«¯ï¼ŒèŠ‚çœäº†æœåŠ¡å™¨èµ„æºã€‚

---

## 6. å¿«é€Ÿå…¥é—¨æŒ‡å—

### 6.1. ç³»ç»Ÿè¦æ±‚

-   **æœåŠ¡å™¨**: æ¨èä½¿ç”¨å¸¦å…¬ç½‘IPçš„äº‘æœåŠ¡å™¨ï¼ˆå¦‚é˜¿é‡Œäº‘ã€è…¾è®¯äº‘ç­‰ï¼‰ã€‚
-   **è®¡ç®—èµ„æº**:
    -   **æœ€ä½**: 2æ ¸, 4GB RAM (çº¯APIè°ƒç”¨)
    -   **æ¨è**: 4æ ¸, 8GB RAM (è‹¥è¿è¡Œæœ¬åœ°ASR/TTSæ¨¡å‹)
-   **æ“ä½œç³»ç»Ÿ**: Linux (Ubuntu, CentOS ç­‰)
-   **Python**: 3.8+ ç‰ˆæœ¬

### 6.2. å®‰è£…æ­¥éª¤

1.  **è·å–æ™ºè°±AI API Key**
    è®¿é—® [æ™ºè°±AIå¼€æ”¾å¹³å°](https://open.bigmodel.cn) æ³¨å†Œå¹¶åˆ›å»ºæ‚¨çš„API Keyã€‚

2.  **å…‹éš†ä»“åº“**
    ```bash
    git clone [https://github.com/your-username/GLM-Xiaozhi.git](https://github.com/your-username/GLM-Xiaozhi.git)
    cd GLM-Xiaozhi
    ```

3.  **å®‰è£…ä¾èµ–**
    å¼ºçƒˆå»ºè®®ä½¿ç”¨Pythonè™šæ‹Ÿç¯å¢ƒã€‚
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    pip install -r requirements.txt
    ```

4.  **é…ç½®API Keyå’Œè®¾ç½®**
    æœ¬é¡¹ç›®ä½¿ç”¨è¦†ç›–ç³»ç»Ÿä»¥ä¿æŠ¤æ‚¨çš„å¯†é’¥å®‰å…¨ã€‚
    a. åˆ›å»º `data` ç›®å½•: `mkdir data`
    b. åˆ›å»ºä¸€ä¸ªç©ºçš„è¦†ç›–é…ç½®æ–‡ä»¶: `touch data/.config.yaml`
    c. ä»ä¸» `config.yaml` å¤åˆ¶æ‚¨éœ€è¦ä¿®æ”¹çš„éƒ¨åˆ†åˆ° `data/.config.yaml` å¹¶å¡«å…¥æ‚¨çš„å¯†é’¥ã€‚

    **`data/.config.yaml` ç¤ºä¾‹:**
    ```yaml
    LLM:
      GLM-45:
        api_key: "YOUR_ZHIPU_API_KEY"
      ChatGLMLLM:
        api_key: "YOUR_ZHIPU_API_KEY"

    VLLM:
      ChatGLMVLLM:
        api_key: "YOUR_ZHIPU_API_KEY"

    ASR:
      GLMASR:
        api_key: "YOUR_ZHIPU_API_KEY"

    autoglm:
      api_key: "YOUR_AUTOGLM_TOKEN"
    ```

5.  **å¯åŠ¨æœåŠ¡å™¨**
    ```bash
    python app.py
    ```
    æˆåŠŸå¯åŠ¨åï¼Œæ§åˆ¶å°å°†æ˜¾ç¤ºWebSocketå’ŒHTTP APIåœ°å€ã€‚

    **ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œæ¨èä½¿ç”¨ `nohup` æˆ– `systemd` ç­‰è¿›ç¨‹ç®¡ç†å™¨åœ¨åå°è¿è¡ŒæœåŠ¡ã€‚**

### 6.3. è¿æ¥æ‚¨çš„ESP32è®¾å¤‡

å°†æ‚¨çš„æœåŠ¡å™¨å…¬ç½‘IPå’Œç«¯å£é…ç½®åˆ°ESP32è®¾å¤‡ã€‚æ‚¨å¯ä»¥ä½¿ç”¨é¡¹ç›®æä¾›çš„ç½‘é¡µOTAå·¥å…·ï¼Œæˆ–é€šè¿‡ `idf.py menuconfig` ç›´æ¥è®¾ç½®ã€‚

-   **WebSocket URL**: `ws://YOUR_SERVER_IP:8000/xiaozhi/v1/`
-   **Vision API URL**: `http://YOUR_SERVER_IP:8003/mcp/vision/explain`

---

## 7. ç‰¹è‰²åŠŸèƒ½

### 7.1. "å°å¹³è€å¸ˆ" æ¨¡å¼
é»˜è®¤çš„äººæ ¼æ˜¯â€œå°å¹³è€å¸ˆâ€ï¼Œä¸€ä½ç²¾é€šæ™ºè°±AIæŠ€æœ¯ã€çƒ­çˆ±æ•™å­¦ä¸ç§‘æŠ€çš„ä¸“å®¶ã€‚

-   **æŠ€æœ¯è§£è¯»**: "å°å¹³è€å¸ˆï¼Œèƒ½è§£é‡Šä¸€ä¸‹`glm-4.5-air`æ¨¡å‹çš„ç‰¹ç‚¹å—ï¼Ÿ"
-   **ç¼–ç¨‹è¾…åŠ©**: "å°å¹³è€å¸ˆï¼Œå¸®æˆ‘å†™ä¸€ä¸ªå¿«é€Ÿæ’åºçš„Pythonå‡½æ•°ã€‚"
-   **é¡¹ç›®å»ºè®®**: "å°å¹³è€å¸ˆï¼Œæˆ‘æ­£åœ¨åšä¸€ä¸ªæ™ºèƒ½å®¶å±…è®¾å¤‡ï¼Œæœ‰ä»€ä¹ˆå»ºè®®ï¼Ÿ"

æ‚¨å¯ä»¥åœ¨ `config.yaml` çš„ `prompt` éƒ¨åˆ†è‡ªç”±å®šåˆ¶æ­¤è§’è‰²ã€‚

### 7.2. éŸ³ä¹ä¸åª’ä½“æ§åˆ¶

-   **æœ¬åœ°éŸ³ä¹**: å°† `.mp3` æ–‡ä»¶æ”¾å…¥ `music` ç›®å½•ï¼Œç„¶åè¯´â€œæ’­æ”¾éŸ³ä¹â€ã€‚
-   **åœ¨çº¿éŸ³ä¹**: ä½¿ç”¨ **AutoGLM** åŠŸèƒ½ç²¾ç¡®æ§åˆ¶æ‰‹æœºä¸Šçš„éŸ³ä¹Appï¼šâ€œæ‰“å¼€Spotifyæ’­æ”¾æˆ‘çš„æ¯å‘¨å‘ç°æ­Œå•ã€‚â€

### 7.3. è®°å¿†åŠŸèƒ½

-   **çŸ­æœŸè®°å¿†**: å°æ™ºèƒ½å¤Ÿè®°ä½å½“å‰å¯¹è¯çš„ä¸Šä¸‹æ–‡ï¼Œå®ç°æµç•…çš„å¤šè½®å¯¹è¯ï¼Œç”± `mem_local_short` æ¨¡å—æä¾›æ”¯æŒã€‚
-   **é•¿æœŸè®°å¿† (è§„åˆ’ä¸­)**: æœªæ¥ç‰ˆæœ¬è®¡åˆ’é›†æˆ `mem0ai` æˆ–æœ¬åœ°æ•°æ®åº“ï¼Œè®©å°æ™ºè®°ä½æ‚¨çš„åå¥½ï¼Œæˆä¸ºä¸€ä¸ªçœŸæ­£æ‡‚æ‚¨çš„ä¸ªæ€§åŒ–åŠ©ç†ã€‚

---

## 8. å·²çŸ¥é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

æ ¹æ®æˆ‘ä»¬çš„æµ‹è¯•ï¼Œ`GLM-4-Voice` æ¨¡å‹å¶å°”å¯èƒ½ä¼šé‡åˆ°APIé”™è¯¯ã€‚

-   **é—®é¢˜**: APIè°ƒç”¨æœ‰æ—¶ä¼šå¤±è´¥ï¼Œå¯¼è‡´TTSåˆæˆä¸­æ–­ã€‚
-   **ä¸´æ—¶æ–¹æ¡ˆ**: æˆ‘ä»¬å»ºè®®åœ¨ `config.yaml` ä¸­å°† `cogtts` è®¾ç½®ä¸ºæ‚¨çš„é»˜è®¤TTSæä¾›è€…ã€‚å®ƒå·²è¢«è¯æ˜é«˜åº¦ç¨³å®šä¸”æ•ˆæœå‡ºè‰²ã€‚æˆ‘ä»¬æ­£ä¸æ™ºè°±AIå›¢é˜Ÿç§¯ææ²Ÿé€šä»¥è§£å†³æ­¤é—®é¢˜ã€‚

---

ç¥æ‚¨ç©å¾—å¼€å¿ƒï¼æ¬¢è¿é€šè¿‡GitHub Issuesè´¡çŒ®ä»£ç å’Œåé¦ˆã€‚
>>>>>>> ef0082b (docs: note that large model files are excluded and how to add them)

### ğŸ§  AI Models / AIæ¨¡å‹
- **Language Models / è¯­è¨€æ¨¡å‹**: GLM-4.5 series (Flash, Air, Plus, X)
- **Vision Models / è§†è§‰æ¨¡å‹**: GLM-4V-Flash, GLM-4.5V
- **Multi-modal Support / å¤šæ¨¡æ€æ”¯æŒ**: Image understanding and analysis

<<<<<<< HEAD
### ğŸ”§ System Features / ç³»ç»ŸåŠŸèƒ½
- **AutoGLM Integration / AutoGLMé›†æˆ**: Device control via MCP protocol
- **Memory System / è®°å¿†ç³»ç»Ÿ**: Short-term conversation memory
- **Music Playback / éŸ³ä¹æ’­æ”¾**: Local and online music support
- **OTA Updates / OTAæ›´æ–°**: Web-based configuration interface
=======

## Performance Benchmarks / æ€§èƒ½æµ‹è¯•
>>>>>>> ef0082b (docs: note that large model files are excluded and how to add them)

---

<<<<<<< HEAD
## Quick Start / å¿«é€Ÿå¼€å§‹

### Prerequisites / ç¯å¢ƒè¦æ±‚

**Hardware Requirements / ç¡¬ä»¶è¦æ±‚:**
- Minimum / æœ€ä½é…ç½®: 2 cores, 4GB RAM (API-only mode)
- Recommended / æ¨èé…ç½®: 4 cores, 8GB RAM (with local models)
- Storage / å­˜å‚¨ç©ºé—´: 10GB+ available space
=======
### LLM Performance / è¯­è¨€æ¨¡å‹æ€§èƒ½

Test query / æµ‹è¯•è¯­å¥: "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"

| Model / æ¨¡å‹    | Total Time / æ€»è€—æ—¶ | First Token / é¦–Token | Success Rate / æˆåŠŸç‡ |
|  | - |  |  |
| **GLM-45-AirX** | 1.682s              | 1.297s                | 100% (3/3)            |
| **GLM-45-Air**  | 1.856s              | 1.394s                | 100% (3/3)            |
| **ChatGLMLLM**  | 2.035s              | 0.739s                | 100% (3/3)            |
| **GLM-4-Plus**  | 2.134s              | 0.585s                | 100% (3/3)            |

### Vision Model Performance / è§†è§‰æ¨¡å‹æ€§èƒ½

| Model / æ¨¡å‹ | Response Time / å“åº”æ—¶é—´ | Stability / ç¨³å®šæ€§ |
| ------------ ||  |
| **ChatGLMVLLM**      | 3.221s                   | 0.483              |
| **GLM-41V-Thinking** | 6.820s                   | 0.523              |
| **GLM-45V**          | 6.923s                   | 0.343              |

### ASR Performance / è¯­éŸ³è¯†åˆ«æ€§èƒ½

| Model / æ¨¡å‹ | Average Time / å¹³å‡è€—æ—¶ | Type / ç±»å‹ |
| ------------ | ----------------------- ||
| **SherpaASR** | 2.867s                  | Local / æœ¬åœ° |
| **FunASR**    | 3.058s                  | Local / æœ¬åœ° |
| **GLMASR**    | 4.374s                  | API / äº‘ç«¯   |



## AutoGLM Integration / AutoGLMé›†æˆ

### Overview / æ¦‚è¿°

AutoGLM transforms Xiaozhi from a simple voice assistant into an intelligent agent capable of controlling your devices through natural language commands.

AutoGLMå°†å°æ™ºä»ç®€å•çš„è¯­éŸ³åŠ©æ‰‹å‡çº§ä¸ºèƒ½å¤Ÿé€šè¿‡è‡ªç„¶è¯­è¨€æ§åˆ¶è®¾å¤‡çš„æ™ºèƒ½ä»£ç†ã€‚

### How It Works / å·¥ä½œåŸç†

```mermaid
graph TD
    A[User Voice Command<br/>ç”¨æˆ·è¯­éŸ³æŒ‡ä»¤] --> B{LLM Intent Recognition<br/>æ„å›¾è¯†åˆ«}
    B -->|Detected Control Intent<br/>è¯†åˆ«åˆ°æ§åˆ¶æ„å›¾| C[Call autoglm_control Function<br/>è°ƒç”¨æ§åˆ¶å‡½æ•°]
    C -->|Send Task Description<br/>å‘é€ä»»åŠ¡æè¿°| D[MCP Client<br/>MCPå®¢æˆ·ç«¯]
    D -->|HTTP POST Request<br/>HTTPè¯·æ±‚| E[AutoGLM Agent Server<br/>AutoGLMæœåŠ¡å™¨]
    E --> F[Execute Automation<br/>æ‰§è¡Œè‡ªåŠ¨åŒ–ä»»åŠ¡]
    F --> G[Return Status<br/>è¿”å›çŠ¶æ€]
    G --> H[Generate Response<br/>ç”Ÿæˆå“åº”]
    H --> I[TTS & Playback<br/>è¯­éŸ³åˆæˆå¹¶æ’­æ”¾]
```

### Example Commands / ç¤ºä¾‹å‘½ä»¤

- "æ‰“å¼€ç½‘æ˜“äº‘éŸ³ä¹" / "Open NetEase Music"
- "å¸®æˆ‘æ‰“å¼€å¾®ä¿¡å¹¶å‘é€æ¶ˆæ¯" / "Open WeChat and send a message"
- "æŸ¥çœ‹ä»Šå¤©çš„æ—¥ç¨‹å®‰æ’" / "Check today's schedule"
- "è®¾ç½®æ˜å¤©æ—©ä¸Š8ç‚¹çš„é—¹é’Ÿ" / "Set an alarm for 8 AM tomorrow"

### Configuration / é…ç½®

The core control logic is implemented in `plugins_func/functions/autoglm_control.py`:

```python
@register_function
async def autoglm_control(task_description: str, action: str = "start_task"):
    """
    Control devices through AutoGLM
    é€šè¿‡AutoGLMæ§åˆ¶è®¾å¤‡
    """
    # Implementation details...
```
>>>>>>> ef0082b (docs: note that large model files are excluded and how to add them)

**Software Requirements / è½¯ä»¶è¦æ±‚:**
- OS / æ“ä½œç³»ç»Ÿ: Linux (Ubuntu 20.04+, CentOS 7+, Alibaba Cloud Linux)
- Python: 3.8+
- Network / ç½‘ç»œ: Public IP with open ports (8000, 8003)

### Installation Steps / å®‰è£…æ­¥éª¤

#### 1. Obtain Zhipu AI API Key / è·å–æ™ºè°±AI APIå¯†é’¥

<<<<<<< HEAD
Visit [Zhipu AI Platform](https://open.bigmodel.cn) to register and create your API key.

è®¿é—®[æ™ºè°±å¼€æ”¾å¹³å°](https://open.bigmodel.cn)æ³¨å†Œå¹¶åˆ›å»ºAPIå¯†é’¥ã€‚
=======
##  ç¡¬ä»¶é…ç½® (ESP32S3) Device Configuration

#### Method 1: OTA Web Configuration / æ–¹æ³•1ï¼šOTAç½‘é¡µé…ç½®

1. Access / è®¿é—®: `http://YOUR_IP:8003/xiaozhi/ota/`
2. Enter WebSocket address / è¾“å…¥WebSocketåœ°å€
3. Save configuration / ä¿å­˜é…ç½®

#### Method 2: ESP-IDF Configuration / æ–¹æ³•2ï¼šESP-IDFé…ç½®

```bash
# Configure via menuconfig / é€šè¿‡menuconfigé…ç½®
idf.py menuconfig

# Build and flash / ç¼–è¯‘å¹¶çƒ§å½•
idf.py build
idf.py flash

# Monitor output / ç›‘æ§è¾“å‡º
idf.py monitor
```

### Configuration / æœåŠ¡å™¨é…ç½®

**Solutions / è§£å†³æ–¹æ¡ˆ:**
```bash
# Check firewall settings / æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
sudo firewall-cmd --add-port=8000/tcp --permanent
sudo firewall-cmd --add-port=8003/tcp --permanent
sudo firewall-cmd --reload

# Verify server is running / éªŒè¯æœåŠ¡å™¨è¿è¡ŒçŠ¶æ€
netstat -antp | grep python
```

### Logging and Debugging / æ—¥å¿—å’Œè°ƒè¯•

```bash
# View real-time logs / æŸ¥çœ‹å®æ—¶æ—¥å¿—
tail -f xiaozhi.log

# Check error logs / æ£€æŸ¥é”™è¯¯æ—¥å¿—
grep ERROR xiaozhi.log

# Monitor system resources / ç›‘æ§ç³»ç»Ÿèµ„æº
htop

# Check Python processes / æ£€æŸ¥Pythonè¿›ç¨‹
ps aux | grep python
```


### Music Control / éŸ³ä¹æ§åˆ¶

- **Local Music / æœ¬åœ°éŸ³ä¹**: Place `.mp3` files in the `music` folder
- **Online Music / åœ¨çº¿éŸ³ä¹**: stream music online
- **Voice Commands / è¯­éŸ³å‘½ä»¤**: "æ’­æ”¾éŸ³ä¹" / "Play music"

### Memory System / è®°å¿†ç³»ç»Ÿ

- **Short-term Memory / çŸ­æœŸè®°å¿†**: Current conversation context
- **Long-term Memory / é•¿æœŸè®°å¿†** (Planned): User preferences and habits


## Development / å¼€å‘

### Provider Architecture / Provideræ¶æ„

The system uses a modular Provider pattern for easy extension:

```python
# Example: Custom LLM Provider
class CustomLLMProvider(BaseLLMProvider):
    async def response(self, prompt: str):
        # Implementation
        pass
    
    async def response_with_functions(self, prompt: str, functions: list):
        # Implementation with function calling
        pass
```

### Adding New Models / æ·»åŠ æ–°æ¨¡å‹

1. Create provider class in appropriate directory / åœ¨ç›¸åº”ç›®å½•åˆ›å»ºProviderç±»
2. Implement required interfaces / å®ç°å¿…è¦æ¥å£
3. Register in configuration / åœ¨é…ç½®ä¸­æ³¨å†Œ
4. Update selected modules / æ›´æ–°é€‰æ‹©çš„æ¨¡å—
>>>>>>> ef0082b (docs: note that large model files are excluded and how to add them)

#### 2. Clone Repository / å…‹éš†é¡¹ç›®

```bash
# Clone the repository / å…‹éš†ä»“åº“
git clone https://github.com/YOUR_USERNAME/GLM-Xiaozhi.git
cd GLM-Xiaozhi

<<<<<<< HEAD
# Add upstream repository / æ·»åŠ ä¸Šæ¸¸ä»“åº“
git remote add upstream https://github.com/78/xiaozhi-esp32-server.git
```
=======
>>>>>>> ef0082b (docs: note that large model files are excluded and how to add them)

#### 3. Setup Python Environment / è®¾ç½®Pythonç¯å¢ƒ

<<<<<<< HEAD
```bash
# Create virtual environment / åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate

# Install dependencies / å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

#### 4. Configure API Keys / é…ç½®APIå¯†é’¥
=======
## Acknowledgments 

This project is based on the original project's open-source license. We thank [@78](https://github.com/78) for the original contribution.
æœ¬é¡¹ç›®åŸºäºåŸé¡¹ç›®çš„å¼€æºåè®®ï¼Œæ„Ÿè°¢è™¾å“¥çš„å¼€æºè´¡çŒ®ã€‚

- **[@78 (è™¾å“¥)](https://github.com/78)** - Original Xiaozhi AI Voice Assistant creator / å°æ™ºAIè¯­éŸ³åŠ©æ‰‹åŸä½œè€…
- **[Zhipu AI / æ™ºè°±AI](https://www.zhipuai.cn/)** - Powerful AI model support / å¼ºå¤§çš„AIæ¨¡å‹æ”¯æŒ
- **All contributors and users / æ‰€æœ‰è´¡çŒ®è€…å’Œä½¿ç”¨è€…ï¼ˆä¸€ä¸‹ä»…ä¸ºéƒ¨åˆ†ï¼‰**
    - [Original Project / åŸé¡¹ç›®](https://github.com/78/xiaozhi-esp32)
    - [Server Repository / æœåŠ¡å™¨ç«¯](https://github.com/78/xiaozhi-esp32-server)
    - [Zhipu AI Documentation / æ™ºè°±AIæ–‡æ¡£](https://open.bigmodel.cn/dev/api)
    - [ESP32 Documentation / ESP32æ–‡æ¡£](https://docs.espressif.com/projects/esp-idf/zh_CN/latest/esp32/)
    - [Hardware Tutorial / ç¡¬ä»¶åˆ¶ä½œæ•™ç¨‹](https://github.com/78/xiaozhi-esp32)
    

<div align="center">

**âš ï¸ Note / æ³¨æ„**

This project is for learning and research purposes only.

æœ¬é¡¹ç›®ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ã€‚

Made with â¤ï¸ by the Xiaozhi Community

</div>
>>>>>>> ef0082b (docs: note that large model files are excluded and how to add them)

Create a secure configuration override:

<<<<<<< HEAD
```bash
# Create data directory / åˆ›å»ºæ•°æ®ç›®å½•
mkdir data

# Create override config / åˆ›å»ºè¦†ç›–é…ç½®
touch data/.config.yaml
```

Edit `data/.config.yaml`:

```yaml
# Zhipu AI Configuration / æ™ºè°±AIé…ç½®
LLM:
  GLM-45:
    api_key: "your-zhipu-api-key-here"
    temperature: 0.7  # Optional / å¯é€‰
    max_tokens: 2048  # Optional / å¯é€‰
  
  ChatGLMLLM:
    api_key: "your-zhipu-api-key-here"

VLLM:
  ChatGLMVLLM:
    api_key: "your-zhipu-api-key-here"

ASR:
  GLMASR:
    api_key: "your-zhipu-api-key-here"

TTS:
  CogTTS:
    api_key: "your-zhipu-api-key-here"

# AutoGLM Configuration (Optional)
autoglm:
  api_key: "your-autoglm-token"
  base_url: "http://your-autoglm-server:port"
```

#### 5. Start the Server / å¯åŠ¨æœåŠ¡å™¨

```bash
# Direct run / ç›´æ¥è¿è¡Œ
python app.py

# Background run / åå°è¿è¡Œ
nohup python app.py > xiaozhi.log 2>&1 &

# Using systemd (Recommended / æ¨è)
sudo systemctl start glm-xiaozhi
sudo systemctl enable glm-xiaozhi  # Auto-start on boot / å¼€æœºè‡ªå¯
```

### Service Endpoints / æœåŠ¡ç«¯ç‚¹

After successful startup, the following endpoints will be available:

| Endpoint / ç«¯ç‚¹ | URL | Description / æè¿° |
|----------------|-----|-------------------|
| WebSocket | `ws://YOUR_IP:8000/xiaozhi/v1/` | Real-time audio streaming / å®æ—¶éŸ³é¢‘æµ |
| Vision API | `http://YOUR_IP:8003/mcp/vision/explain` | Image analysis / å›¾åƒåˆ†æ |
| OTA Config | `http://YOUR_IP:8003/xiaozhi/ota/` | Web configuration / ç½‘é¡µé…ç½® |
| Test Tool | `http://YOUR_IP:8003/xiaozhi/ota/` | Service testing / æœåŠ¡æµ‹è¯• |

---

## Model Selection Guide / æ¨¡å‹é€‰æ‹©æŒ‡å—

Choose the optimal model configuration based on your requirements:

### Language Models (LLM) / è¯­è¨€æ¨¡å‹

| Model / æ¨¡å‹ | Speed / é€Ÿåº¦ | Intelligence / æ™ºèƒ½ | Cost / æˆæœ¬ | Use Case / ä½¿ç”¨åœºæ™¯ |
|-------------|-------------|-------------------|------------|-------------------|
| **glm-4-flash** | âš¡âš¡âš¡âš¡âš¡ | â­â­â­ | ğŸ’° | Quick responses, daily Q&A / å¿«é€Ÿå“åº”ï¼Œæ—¥å¸¸é—®ç­” |
| **glm-4.5-flash** | âš¡âš¡âš¡âš¡âš¡ | â­â­â­ | ğŸ’° | Fast interactions / å¿«é€Ÿäº¤äº’ |
| **glm-4.5-air** | âš¡âš¡âš¡âš¡ | â­â­â­â­ | ğŸ’°ğŸ’° | **Balanced choice** / **å¹³è¡¡ä¹‹é€‰** |
| **glm-4.5-airx** | âš¡âš¡âš¡âš¡ | â­â­â­â­â­ | ğŸ’°ğŸ’° | Complex tasks / å¤æ‚ä»»åŠ¡ |
| **glm-4-plus** | âš¡âš¡âš¡ | â­â­â­â­â­ | ğŸ’°ğŸ’°ğŸ’° | Professional analysis / ä¸“ä¸šåˆ†æ |
| **glm-4.5-x** | âš¡âš¡ | â­â­â­â­â­ | ğŸ’°ğŸ’°ğŸ’°ğŸ’° | Maximum capability / æœ€å¼ºèƒ½åŠ› |

### Vision Models (VLLM) / è§†è§‰æ¨¡å‹

| Model / æ¨¡å‹ | Response Time / å“åº”æ—¶é—´ | Capability / èƒ½åŠ› | Recommended / æ¨èåº¦ |
|-------------|------------------------|------------------|-------------------|
| **glm-4v-flash** | 3.2s | Basic vision / åŸºç¡€è§†è§‰ | â˜…â˜…â˜…â˜…â˜… |
| **glm-4.1v-thinking-flash** | 6.8s | Reasoning / æ¨ç†åˆ†æ | â˜…â˜…â˜…â˜…â˜† |
| **glm-4.5v** | 6.9s | Advanced / é«˜çº§åˆ†æ | â˜…â˜…â˜…â˜…â˜† |

### Audio Models / éŸ³é¢‘æ¨¡å‹

| Type / ç±»å‹ | Model / æ¨¡å‹ | Cost / æˆæœ¬ | Quality / è´¨é‡ | Privacy / éšç§ |
|------------|-------------|------------|---------------|---------------|
| **ASR** | GLMASR (API) | Pay-per-use / æŒ‰é‡ä»˜è´¹ | â˜…â˜…â˜…â˜…â˜… | Cloud / äº‘ç«¯ |
| **ASR** | FunASR (Local) | Free / å…è´¹ | â˜…â˜…â˜…â˜…â˜† | Local / æœ¬åœ° |
| **TTS** | CogTTS | Pay-per-use / æŒ‰é‡ä»˜è´¹ | â˜…â˜…â˜…â˜…â˜… | Cloud / äº‘ç«¯ |
| **TTS** | EdgeTTS | Free / å…è´¹ | â˜…â˜…â˜…â˜†â˜† | Microsoft / å¾®è½¯ |

---

## Performance Benchmarks / æ€§èƒ½æµ‹è¯•

All tests conducted on 4-core 8GB cloud server / æ‰€æœ‰æµ‹è¯•åœ¨4æ ¸8GBäº‘æœåŠ¡å™¨ä¸Šè¿›è¡Œ

### LLM Performance / è¯­è¨€æ¨¡å‹æ€§èƒ½

Test query / æµ‹è¯•è¯­å¥: "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"

| Model / æ¨¡å‹ | Total Time / æ€»è€—æ—¶ | First Token / é¦–Token | Success Rate / æˆåŠŸç‡ |
|-------------|-------------------|---------------------|---------------------|
| **GLM-45-AirX** | 1.682s | 1.297s | 100% (3/3) |
| **GLM-45-Air** | 1.856s | 1.394s | 100% (3/3) |
| **ChatGLMLLM** | 2.035s | 0.739s | 100% (3/3) |
| **GLM-4-Plus** | 2.134s | 0.585s | 100% (3/3) |

### Vision Model Performance / è§†è§‰æ¨¡å‹æ€§èƒ½

| Model / æ¨¡å‹ | Response Time / å“åº”æ—¶é—´ | Stability / ç¨³å®šæ€§ |
|-------------|------------------------|-------------------|
| **ChatGLMVLLM** | 3.221s | 0.483 |
| **GLM-41V-Thinking** | 6.820s | 0.523 |
| **GLM-45V** | 6.923s | 0.343 |

### ASR Performance / è¯­éŸ³è¯†åˆ«æ€§èƒ½

| Model / æ¨¡å‹ | Average Time / å¹³å‡è€—æ—¶ | Type / ç±»å‹ |
|-------------|----------------------|------------|
| **SherpaASR** | 2.867s | Local / æœ¬åœ° |
| **FunASR** | 3.058s | Local / æœ¬åœ° |
| **GLMASR** | 4.374s | API / äº‘ç«¯ |

---

## AutoGLM Integration / AutoGLMé›†æˆ

### Overview / æ¦‚è¿°

AutoGLM transforms Xiaozhi from a simple voice assistant into an intelligent agent capable of controlling your devices through natural language commands.

AutoGLMå°†å°æ™ºä»ç®€å•çš„è¯­éŸ³åŠ©æ‰‹å‡çº§ä¸ºèƒ½å¤Ÿé€šè¿‡è‡ªç„¶è¯­è¨€æ§åˆ¶è®¾å¤‡çš„æ™ºèƒ½ä»£ç†ã€‚

### How It Works / å·¥ä½œåŸç†

```mermaid
graph TD
    A[User Voice Command<br/>ç”¨æˆ·è¯­éŸ³æŒ‡ä»¤] --> B{LLM Intent Recognition<br/>æ„å›¾è¯†åˆ«}
    B -->|Detected Control Intent<br/>è¯†åˆ«åˆ°æ§åˆ¶æ„å›¾| C[Call autoglm_control Function<br/>è°ƒç”¨æ§åˆ¶å‡½æ•°]
    C -->|Send Task Description<br/>å‘é€ä»»åŠ¡æè¿°| D[MCP Client<br/>MCPå®¢æˆ·ç«¯]
    D -->|HTTP POST Request<br/>HTTPè¯·æ±‚| E[AutoGLM Agent Server<br/>AutoGLMæœåŠ¡å™¨]
    E --> F[Execute Automation<br/>æ‰§è¡Œè‡ªåŠ¨åŒ–ä»»åŠ¡]
    F --> G[Return Status<br/>è¿”å›çŠ¶æ€]
    G --> H[Generate Response<br/>ç”Ÿæˆå“åº”]
    H --> I[TTS & Playback<br/>è¯­éŸ³åˆæˆå¹¶æ’­æ”¾]
```

### Example Commands / ç¤ºä¾‹å‘½ä»¤

- "æ‰“å¼€ç½‘æ˜“äº‘éŸ³ä¹" / "Open NetEase Music"
- "å¸®æˆ‘æ‰“å¼€å¾®ä¿¡å¹¶å‘é€æ¶ˆæ¯" / "Open WeChat and send a message"
- "æŸ¥çœ‹ä»Šå¤©çš„æ—¥ç¨‹å®‰æ’" / "Check today's schedule"
- "è®¾ç½®æ˜å¤©æ—©ä¸Š8ç‚¹çš„é—¹é’Ÿ" / "Set an alarm for 8 AM tomorrow"

### Configuration / é…ç½®

The core control logic is implemented in `plugins_func/functions/autoglm_control.py`:

```python
@register_function
async def autoglm_control(task_description: str, action: str = "start_task"):
    """
    Control devices through AutoGLM
    é€šè¿‡AutoGLMæ§åˆ¶è®¾å¤‡
    """
    # Implementation details...
```

---

## Configuration / é…ç½®

### ESP32 Device Configuration / ESP32è®¾å¤‡é…ç½®

#### Method 1: OTA Web Configuration / æ–¹æ³•1ï¼šOTAç½‘é¡µé…ç½®

1. Access / è®¿é—®: `http://YOUR_IP:8003/xiaozhi/ota/`
2. Enter WebSocket address / è¾“å…¥WebSocketåœ°å€
3. Save configuration / ä¿å­˜é…ç½®

#### Method 2: ESP-IDF Configuration / æ–¹æ³•2ï¼šESP-IDFé…ç½®

```bash
# Configure via menuconfig / é€šè¿‡menuconfigé…ç½®
idf.py menuconfig

# Build and flash / ç¼–è¯‘å¹¶çƒ§å½•
idf.py build
idf.py flash

# Monitor output / ç›‘æ§è¾“å‡º
idf.py monitor
```

### Server Configuration / æœåŠ¡å™¨é…ç½®

Main configuration file structure / ä¸»é…ç½®æ–‡ä»¶ç»“æ„:

```yaml
# config.yaml
selected_module:
  llm_module_name: "ChatGLMLLM"  # LLM provider
  asr_module_name: "GLMASR"      # ASR provider
  tts_module_name: "CogTTS"      # TTS provider
  vllm_module_name: "ChatGLMVLLM" # Vision provider

# Model-specific configurations
LLM:
  ChatGLMLLM:
    model_name: "glm-4-flash"
    api_key: ""  # Set in data/.config.yaml
    temperature: 0.7
    max_tokens: 2048

# System settings
GENERAL:
  vad_threshold: 0.5
  audio_format: "pcm"
  sample_rate: 16000
```

---

## Troubleshooting / æ•…éšœæ’é™¤

### Common Issues / å¸¸è§é—®é¢˜

#### 1. WebSocket Connection Failed / WebSocketè¿æ¥å¤±è´¥

**Symptoms / ç—‡çŠ¶:**
- ESP32 cannot connect to server / ESP32æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨
- Connection timeout errors / è¿æ¥è¶…æ—¶é”™è¯¯

**Solutions / è§£å†³æ–¹æ¡ˆ:**
```bash
# Check firewall settings / æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
sudo firewall-cmd --add-port=8000/tcp --permanent
sudo firewall-cmd --add-port=8003/tcp --permanent
sudo firewall-cmd --reload

# Verify server is running / éªŒè¯æœåŠ¡å™¨è¿è¡ŒçŠ¶æ€
netstat -antp | grep python
```

#### 2. GLM-4-Voice Issues / GLM-4-Voiceé—®é¢˜

**Known Issue / å·²çŸ¥é—®é¢˜:**
- API may return errors in certain conditions
- APIåœ¨ç‰¹å®šæ¡ä»¶ä¸‹å¯èƒ½è¿”å›é”™è¯¯

**Temporary Solution / ä¸´æ—¶æ–¹æ¡ˆ:**
- Use CogTTS as primary TTS provider
- ä½¿ç”¨CogTTSä½œä¸ºä¸»è¦TTSæä¾›è€…

#### 3. High Latency / é«˜å»¶è¿Ÿ

**Optimization Steps / ä¼˜åŒ–æ­¥éª¤:**
1. Switch to faster models (Flash series) / åˆ‡æ¢åˆ°æ›´å¿«çš„æ¨¡å‹ï¼ˆFlashç³»åˆ—ï¼‰
2. Enable local ASR if possible / å¦‚å¯èƒ½å¯ç”¨æœ¬åœ°ASR
3. Check network connectivity / æ£€æŸ¥ç½‘ç»œè¿æ¥
4. Monitor server resources / ç›‘æ§æœåŠ¡å™¨èµ„æº

### Logging and Debugging / æ—¥å¿—å’Œè°ƒè¯•

```bash
# View real-time logs / æŸ¥çœ‹å®æ—¶æ—¥å¿—
tail -f xiaozhi.log

# Check error logs / æ£€æŸ¥é”™è¯¯æ—¥å¿—
grep ERROR xiaozhi.log

# Monitor system resources / ç›‘æ§ç³»ç»Ÿèµ„æº
htop

# Check Python processes / æ£€æŸ¥Pythonè¿›ç¨‹
ps aux | grep python
```

---

## Advanced Features / é«˜çº§åŠŸèƒ½

### Custom Personas / è‡ªå®šä¹‰è§’è‰²

The project includes "å°å¹³è€å¸ˆ" (Teacher Xiaoping), an AI assistant persona specialized in:
- Technical explanations / æŠ€æœ¯è®²è§£
- Programming guidance / ç¼–ç¨‹æŒ‡å¯¼
- Project consulting / é¡¹ç›®å’¨è¯¢

Configure custom personas in `config.yaml`:

```yaml
prompt:
  system_prompt: |
    ä½ æ˜¯å°å¹³è€å¸ˆï¼Œä¸€ä½ç²¾é€šæ™ºè°±AIå…¨æ ˆæŠ€æœ¯çš„ä¸“å®¶...
    You are Teacher Xiaoping, an expert in Zhipu AI technologies...
```

### Music Control / éŸ³ä¹æ§åˆ¶

- **Local Music / æœ¬åœ°éŸ³ä¹**: Place `.mp3` files in the `music` folder
- **Online Music / åœ¨çº¿éŸ³ä¹**: Control music apps via AutoGLM
- **Voice Commands / è¯­éŸ³å‘½ä»¤**: "æ’­æ”¾éŸ³ä¹" / "Play music"

### Memory System / è®°å¿†ç³»ç»Ÿ

- **Short-term Memory / çŸ­æœŸè®°å¿†**: Current conversation context
- **Long-term Memory / é•¿æœŸè®°å¿†** (Planned): User preferences and habits

---

## Development / å¼€å‘

### Provider Architecture / Provideræ¶æ„

The system uses a modular Provider pattern for easy extension:

```python
# Example: Custom LLM Provider
class CustomLLMProvider(BaseLLMProvider):
    async def response(self, prompt: str):
        # Implementation
        pass
    
    async def response_with_functions(self, prompt: str, functions: list):
        # Implementation with function calling
        pass
```

### Adding New Models / æ·»åŠ æ–°æ¨¡å‹

1. Create provider class in appropriate directory / åœ¨ç›¸åº”ç›®å½•åˆ›å»ºProviderç±»
2. Implement required interfaces / å®ç°å¿…è¦æ¥å£
3. Register in configuration / åœ¨é…ç½®ä¸­æ³¨å†Œ
4. Update selected modules / æ›´æ–°é€‰æ‹©çš„æ¨¡å—

---

## API Pricing Reference / APIä»·æ ¼å‚è€ƒ

| Service / æœåŠ¡ | Model / æ¨¡å‹ | Pricing / ä»·æ ¼ |
|---------------|-------------|---------------|
| **LLM** | GLM-4-Flash | Â¥0.0001/1K tokens |
| **LLM** | GLM-4.5-Air | Â¥0.001/1K tokens |
| **LLM** | GLM-4-Plus | Â¥0.05/1K tokens |
| **ASR** | GLM-ASR | Â¥0.06/minute |
| **TTS** | CogTTS | Â¥80/1M tokens |
| **Vision** | GLM-4V-Flash | Â¥0.002/1K tokens |

---

## Contributing / è´¡çŒ®

We welcome contributions! Please:

1. Fork the repository / Forkä»“åº“
2. Create a feature branch / åˆ›å»ºç‰¹æ€§åˆ†æ”¯
3. Commit your changes / æäº¤æ›´æ”¹
4. Push to the branch / æ¨é€åˆ°åˆ†æ”¯
5. Create a Pull Request / åˆ›å»ºPull Request

### Development Guidelines / å¼€å‘æŒ‡å—

- Follow PEP 8 style guide / éµå¾ªPEP 8é£æ ¼æŒ‡å—
- Add tests for new features / ä¸ºæ–°åŠŸèƒ½æ·»åŠ æµ‹è¯•
- Update documentation / æ›´æ–°æ–‡æ¡£
- Maintain backward compatibility / ä¿æŒå‘åå…¼å®¹

---

## License / å¼€æºåè®®

This project is based on the original project's open-source license. We thank [@78](https://github.com/78) for the original contribution.

æœ¬é¡¹ç›®åŸºäºåŸé¡¹ç›®çš„å¼€æºåè®®ï¼Œæ„Ÿè°¢è™¾å“¥çš„å¼€æºè´¡çŒ®ã€‚

---

## Acknowledgments / è‡´è°¢

- **[@78 (è™¾å“¥)](https://github.com/78)** - Original Xiaozhi AI Voice Assistant creator / å°æ™ºAIè¯­éŸ³åŠ©æ‰‹åŸä½œè€…
- **[Zhipu AI / æ™ºè°±AI](https://www.zhipuai.cn/)** - Powerful AI model support / å¼ºå¤§çš„AIæ¨¡å‹æ”¯æŒ
- **All contributors and users / æ‰€æœ‰è´¡çŒ®è€…å’Œä½¿ç”¨è€…**

---

## Resources / ç›¸å…³èµ„æº

- [Original Project / åŸé¡¹ç›®](https://github.com/78/xiaozhi-esp32)
- [Server Repository / æœåŠ¡å™¨ç«¯](https://github.com/78/xiaozhi-esp32-server)
- [Zhipu AI Documentation / æ™ºè°±AIæ–‡æ¡£](https://open.bigmodel.cn/dev/api)
- [ESP32 Documentation / ESP32æ–‡æ¡£](https://docs.espressif.com/projects/esp-idf/zh_CN/latest/esp32/)
- [Hardware Tutorial / ç¡¬ä»¶åˆ¶ä½œæ•™ç¨‹](https://github.com/78/xiaozhi-esp32)

---

## Contact & Support / è”ç³»ä¸æ”¯æŒ

- **Issues**: Please submit issues on [GitHub Issues](https://github.com/YOUR_USERNAME/GLM-Xiaozhi/issues)
- **Discussions**: Join our community discussions
- **Email**: your-email@example.com

---

<div align="center">

**âš ï¸ Note / æ³¨æ„**

This project is for learning and research purposes only.

æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ã€‚

---

Made with â¤ï¸ by the Xiaozhi Community

</div>
=======
## Models excluded / æ¨¡å‹æ–‡ä»¶è¯´æ˜

Large model binaries (for example `models/*.pt`, `models/**/*.onnx`) are excluded from this repository and are not tracked by Git to keep the repo lightweight and avoid hitting GitHub size limits.

å¤§å‹æ¨¡å‹äºŒè¿›åˆ¶æ–‡ä»¶ï¼ˆä¾‹å¦‚ `models/*.pt`ã€`models/**/*.onnx`ï¼‰å·²ä»ä»“åº“ä¸­æ’é™¤ï¼ŒæœªåŠ å…¥ Git è·Ÿè¸ªï¼Œä»¥ä¿æŒä»“åº“è½»é‡å¹¶é¿å…è¶…å‡º GitHub å¤§å°é™åˆ¶ã€‚

How to obtain and use models / è·å–ä¸ä½¿ç”¨æ–¹æ³•:

- Download models from the official provider or from your private storage (releases, vendor site, S3, etc.).
- Place downloaded models under the `models/` directory using the expected subfolder names (for example `models/SenseVoiceSmall/` or `models/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/`).
- Ensure correct file permissions and update `config.yaml` if you use custom paths.

å¦‚æœéœ€è¦ä¸åä½œæˆå‘˜å…±äº«å¤§å‹æ¨¡å‹ï¼Œæ¨èä½¿ç”¨ Git LFSã€GitHub Releases æˆ–å¤–éƒ¨å­˜å‚¨æœåŠ¡ï¼ˆä¾‹å¦‚å¯¹è±¡å­˜å‚¨ï¼‰æ¥åˆ†å‘æ¨¡å‹ï¼Œè€Œä¸è¦å°†äºŒè¿›åˆ¶ç›´æ¥æäº¤åˆ°ä»“åº“ã€‚
>>>>>>> ef0082b (docs: note that large model files are excluded and how to add them)
