# GLM-Xiaozhi å°æ™ºAIè¯­éŸ³åŠ©æ‰‹ - æ™ºè°±AIé›†æˆç‰ˆ

<div align="center">

![Xiaozhi Logo](https://img.shields.io/badge/Xiaozhi-GLM-blue)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.8%2B-green)](https://www.python.org/)
[![GLM](https://img.shields.io/badge/GLM-4.5-red)](https://open.bigmodel.cn/)
[![Stars](https://img.shields.io/github/stars/YOUR_USERNAME/xiaozhi-esp32-server-glm?style=social)](https://github.com/YOUR_USERNAME/xiaozhi-esp32-server-glm)

> ğŸ™ï¸ **Open-source intelligent voice assistant powered by ESP32 hardware and Zhipu AI models**
> 
> åŸºäºESP32ç¡¬ä»¶ä¸æ™ºè°±AIå¤§æ¨¡å‹çš„å¼€æºæ™ºèƒ½è¯­éŸ³åŠ©æ‰‹
> 
> Original project by [@78](https://github.com/78) | åŸé¡¹ç›®æ¥è‡ªè™¾å“¥çš„å¼€æºè´¡çŒ®

</div>

---

## ğŸ“Œ Table of Contents / ç›®å½•

- [Project Overview / é¡¹ç›®æ¦‚è¿°](#project-overview--é¡¹ç›®æ¦‚è¿°)
- [System Architecture / ç³»ç»Ÿæ¶æ„](#system-architecture--ç³»ç»Ÿæ¶æ„)
- [Core Features / æ ¸å¿ƒç‰¹æ€§](#core-features--æ ¸å¿ƒç‰¹æ€§)
- [Quick Start / å¿«é€Ÿå¼€å§‹](#quick-start--å¿«é€Ÿå¼€å§‹)
- [Model Selection Guide / æ¨¡å‹é€‰æ‹©æŒ‡å—](#model-selection-guide--æ¨¡å‹é€‰æ‹©æŒ‡å—)
- [Performance Benchmarks / æ€§èƒ½æµ‹è¯•](#performance-benchmarks--æ€§èƒ½æµ‹è¯•)
- [AutoGLM Integration / AutoGLMé›†æˆ](#autoglm-integration--autoglmé›†æˆ)
- [Configuration / é…ç½®](#configuration--é…ç½®)
- [Troubleshooting / æ•…éšœæ’é™¤](#troubleshooting--æ•…éšœæ’é™¤)
- [Contributing / è´¡çŒ®](#contributing--è´¡çŒ®)

---

## Project Overview / é¡¹ç›®æ¦‚è¿°

**GLM-Xiaozhi** is a comprehensive transformation of the [Xiaozhi AI Voice Assistant](https://github.com/78/xiaozhi-esp32) server backend, implementing seamless integration with Zhipu AI's full model suite. This project provides a complete private deployment solution that eliminates dependency on official servers while delivering enhanced conversational, voice, and visual capabilities.

æœ¬é¡¹ç›®æ˜¯å¯¹[å°æ™ºAIè¯­éŸ³åŠ©æ‰‹](https://github.com/78/xiaozhi-esp32)æœåŠ¡å™¨ç«¯çš„å…¨é¢æ”¹é€ ï¼Œå®ç°ä¸æ™ºè°±AIå…¨ç³»åˆ—æ¨¡å‹çš„æ— ç¼å¯¹æ¥ï¼Œæä¾›å®Œå…¨ç§æœ‰åŒ–çš„éƒ¨ç½²æ–¹æ¡ˆã€‚

### ğŸŒŸ Key Highlights / æ ¸å¿ƒäº®ç‚¹

- **ğŸ”’ Complete Privatization / å®Œå…¨ç§æœ‰åŒ–**: Deploy all services on your own server for maximum data privacy
- **ğŸ¤– Zhipu AI Full Stack / æ™ºè°±AIå…¨å®¶æ¡¶**: Integrated support for GLM-4.5 series, voice models, and vision capabilities
- **ğŸ¯ AutoGLM Control / æ™ºèƒ½æ§åˆ¶**: Device automation through MCP protocol integration
- **ğŸ“¦ Modular Architecture / æ¨¡å—åŒ–æ¶æ„**: Easy-to-extend Provider pattern design
- **ğŸš€ Lightweight Deployment / è½»é‡åŒ–éƒ¨ç½²**: Direct source code deployment without Docker dependencies

---

## System Architecture / ç³»ç»Ÿæ¶æ„

### Overall Architecture Diagram / æ•´ä½“æ¶æ„å›¾

```mermaid
graph TB
    subgraph "Hardware Layer / ç¡¬ä»¶å±‚"
        ESP32[ESP32 Device<br/>éº¦å…‹é£ + æ‰¬å£°å™¨<br/>Microphone + Speaker]
    end
    
    subgraph "Server Layer / æœåŠ¡å™¨å±‚"
        WS[WebSocket Server<br/>å®æ—¶éŸ³é¢‘æµå¤„ç†<br/>Real-time Audio Stream]
        HTTP[HTTP Server<br/>è§†è§‰åˆ†æä¸OTA<br/>Vision & OTA]
        AUDIO[Audio Processing<br/>VAD + æ ¼å¼è½¬æ¢<br/>VAD + Format Conversion]
        PROVIDER[Model Providers<br/>æ¨¡å‹æä¾›è€…æ¥å£]
        MCP[AutoGLM MCP Client<br/>è®¾å¤‡æ§åˆ¶å®¢æˆ·ç«¯]
    end
    
    subgraph "Zhipu AI Cloud / æ™ºè°±AIäº‘ç«¯"
        ZHIPU[Zhipu AI API Gateway]
        GLM[GLM-4.5 å¯¹è¯æ¨¡å‹<br/>Dialogue Model]
        ASR[GLM-ASR è¯­éŸ³è¯†åˆ«<br/>Speech Recognition]
        TTS[GLM-4-Voice è¯­éŸ³åˆæˆ<br/>Voice Synthesis]
        VISION[GLM-4V è§†è§‰ç†è§£<br/>Vision Understanding]
    end
    
    ESP32 <-->|WebSocket| WS
    WS <--> AUDIO
    AUDIO <--> PROVIDER
    PROVIDER <--> ZHIPU
    PROVIDER <--> MCP
    ZHIPU --> GLM
    ZHIPU --> ASR
    ZHIPU --> TTS
    ZHIPU --> VISION
```

### Workflow Sequence / å·¥ä½œæµç¨‹

```mermaid
sequenceDiagram
    participant User as User/ç”¨æˆ·
    participant ESP32
    participant Server as GLM-Xiaozhi
    participant ZhipuAI as Zhipu AI

    User->>ESP32: Voice Input / è¯­éŸ³è¾“å…¥
    ESP32->>Server: Audio Stream (WebSocket)
    Server->>Server: VAD Detection / é™éŸ³æ£€æµ‹
    Server->>ZhipuAI: ASR (Speech to Text)
    ZhipuAI-->>Server: Text Result / æ–‡æœ¬ç»“æœ
    Server->>ZhipuAI: LLM Processing / å¤§æ¨¡å‹å¤„ç†
    ZhipuAI-->>Server: AI Response / AIå“åº”
    Server->>ZhipuAI: TTS (Text to Speech)
    ZhipuAI-->>Server: Audio Data / éŸ³é¢‘æ•°æ®
    Server-->>ESP32: Audio Stream
    ESP32-->>User: Voice Output / è¯­éŸ³è¾“å‡º
```

---

## Core Features / æ ¸å¿ƒç‰¹æ€§

### ğŸ¤ Voice Interaction / è¯­éŸ³äº¤äº’
- **ASR (Speech Recognition / è¯­éŸ³è¯†åˆ«)**: GLM-ASR, FunASR, SherpaASR
- **TTS (Text to Speech / è¯­éŸ³åˆæˆ)**: CogTTS, GLM-4-Voice, EdgeTTS
- **VAD (Voice Activity Detection / é™éŸ³æ£€æµ‹)**: Real-time speech boundary detection

### ğŸ§  AI Models / AIæ¨¡å‹
- **Language Models / è¯­è¨€æ¨¡å‹**: GLM-4.5 series (Flash, Air, Plus, X)
- **Vision Models / è§†è§‰æ¨¡å‹**: GLM-4V-Flash, GLM-4.5V
- **Multi-modal Support / å¤šæ¨¡æ€æ”¯æŒ**: Image understanding and analysis

### ğŸ”§ System Features / ç³»ç»ŸåŠŸèƒ½
- **AutoGLM Integration / AutoGLMé›†æˆ**: Device control via MCP protocol
- **Memory System / è®°å¿†ç³»ç»Ÿ**: Short-term conversation memory
- **Music Playback / éŸ³ä¹æ’­æ”¾**: Local and online music support
- **OTA Updates / OTAæ›´æ–°**: Web-based configuration interface

---

## Quick Start / å¿«é€Ÿå¼€å§‹

### Prerequisites / ç¯å¢ƒè¦æ±‚

**Hardware Requirements / ç¡¬ä»¶è¦æ±‚:**
- Minimum / æœ€ä½é…ç½®: 2 cores, 4GB RAM (API-only mode)
- Recommended / æ¨èé…ç½®: 4 cores, 8GB RAM (with local models)
- Storage / å­˜å‚¨ç©ºé—´: 10GB+ available space

**Software Requirements / è½¯ä»¶è¦æ±‚:**
- OS / æ“ä½œç³»ç»Ÿ: Linux (Ubuntu 20.04+, CentOS 7+, Alibaba Cloud Linux)
- Python: 3.8+
- Network / ç½‘ç»œ: Public IP with open ports (8000, 8003)

### Installation Steps / å®‰è£…æ­¥éª¤

#### 1. Obtain Zhipu AI API Key / è·å–æ™ºè°±AI APIå¯†é’¥

Visit [Zhipu AI Platform](https://open.bigmodel.cn) to register and create your API key.

è®¿é—®[æ™ºè°±å¼€æ”¾å¹³å°](https://open.bigmodel.cn)æ³¨å†Œå¹¶åˆ›å»ºAPIå¯†é’¥ã€‚

#### 2. Clone Repository / å…‹éš†é¡¹ç›®

```bash
# Clone the repository / å…‹éš†ä»“åº“
git clone https://github.com/YOUR_USERNAME/GLM-Xiaozhi.git
cd GLM-Xiaozhi

# Add upstream repository / æ·»åŠ ä¸Šæ¸¸ä»“åº“
git remote add upstream https://github.com/78/xiaozhi-esp32-server.git
```

#### 3. Setup Python Environment / è®¾ç½®Pythonç¯å¢ƒ

```bash
# Create virtual environment / åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate

# Install dependencies / å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

#### 4. Configure API Keys / é…ç½®APIå¯†é’¥

Create a secure configuration override:

```bash
# Create data directory / åˆ›å»ºæ•°æ®ç›®å½•
mkdir data

# Create override config / åˆ›å»ºè¦†ç›–é…ç½®
touch data/.config.yaml
```

Edit `data/.config.yaml`:

```yaml
# Zhipu AI Configuration / æ™ºè°±AIé…ç½®
LLM:
  GLM-45:
    api_key: "your-zhipu-api-key-here"
    temperature: 0.7  # Optional / å¯é€‰
    max_tokens: 2048  # Optional / å¯é€‰
  
  ChatGLMLLM:
    api_key: "your-zhipu-api-key-here"

VLLM:
  ChatGLMVLLM:
    api_key: "your-zhipu-api-key-here"

ASR:
  GLMASR:
    api_key: "your-zhipu-api-key-here"

TTS:
  CogTTS:
    api_key: "your-zhipu-api-key-here"

# AutoGLM Configuration (Optional)
autoglm:
  api_key: "your-autoglm-token"
  base_url: "http://your-autoglm-server:port"
```

#### 5. Start the Server / å¯åŠ¨æœåŠ¡å™¨

```bash
# Direct run / ç›´æ¥è¿è¡Œ
python app.py

# Background run / åå°è¿è¡Œ
nohup python app.py > xiaozhi.log 2>&1 &

# Using systemd (Recommended / æ¨è)
sudo systemctl start glm-xiaozhi
sudo systemctl enable glm-xiaozhi  # Auto-start on boot / å¼€æœºè‡ªå¯
```

### Service Endpoints / æœåŠ¡ç«¯ç‚¹

After successful startup, the following endpoints will be available:

| Endpoint / ç«¯ç‚¹ | URL | Description / æè¿° |
|----------------|-----|-------------------|
| WebSocket | `ws://YOUR_IP:8000/xiaozhi/v1/` | Real-time audio streaming / å®æ—¶éŸ³é¢‘æµ |
| Vision API | `http://YOUR_IP:8003/mcp/vision/explain` | Image analysis / å›¾åƒåˆ†æ |
| OTA Config | `http://YOUR_IP:8003/xiaozhi/ota/` | Web configuration / ç½‘é¡µé…ç½® |
| Test Tool | `http://YOUR_IP:8003/xiaozhi/ota/` | Service testing / æœåŠ¡æµ‹è¯• |

---

## Model Selection Guide / æ¨¡å‹é€‰æ‹©æŒ‡å—

Choose the optimal model configuration based on your requirements:

### Language Models (LLM) / è¯­è¨€æ¨¡å‹

| Model / æ¨¡å‹ | Speed / é€Ÿåº¦ | Intelligence / æ™ºèƒ½ | Cost / æˆæœ¬ | Use Case / ä½¿ç”¨åœºæ™¯ |
|-------------|-------------|-------------------|------------|-------------------|
| **glm-4-flash** | âš¡âš¡âš¡âš¡âš¡ | â­â­â­ | ğŸ’° | Quick responses, daily Q&A / å¿«é€Ÿå“åº”ï¼Œæ—¥å¸¸é—®ç­” |
| **glm-4.5-flash** | âš¡âš¡âš¡âš¡âš¡ | â­â­â­ | ğŸ’° | Fast interactions / å¿«é€Ÿäº¤äº’ |
| **glm-4.5-air** | âš¡âš¡âš¡âš¡ | â­â­â­â­ | ğŸ’°ğŸ’° | **Balanced choice** / **å¹³è¡¡ä¹‹é€‰** |
| **glm-4.5-airx** | âš¡âš¡âš¡âš¡ | â­â­â­â­â­ | ğŸ’°ğŸ’° | Complex tasks / å¤æ‚ä»»åŠ¡ |
| **glm-4-plus** | âš¡âš¡âš¡ | â­â­â­â­â­ | ğŸ’°ğŸ’°ğŸ’° | Professional analysis / ä¸“ä¸šåˆ†æ |
| **glm-4.5-x** | âš¡âš¡ | â­â­â­â­â­ | ğŸ’°ğŸ’°ğŸ’°ğŸ’° | Maximum capability / æœ€å¼ºèƒ½åŠ› |

### Vision Models (VLLM) / è§†è§‰æ¨¡å‹

| Model / æ¨¡å‹ | Response Time / å“åº”æ—¶é—´ | Capability / èƒ½åŠ› | Recommended / æ¨èåº¦ |
|-------------|------------------------|------------------|-------------------|
| **glm-4v-flash** | 3.2s | Basic vision / åŸºç¡€è§†è§‰ | â˜…â˜…â˜…â˜…â˜… |
| **glm-4.1v-thinking-flash** | 6.8s | Reasoning / æ¨ç†åˆ†æ | â˜…â˜…â˜…â˜…â˜† |
| **glm-4.5v** | 6.9s | Advanced / é«˜çº§åˆ†æ | â˜…â˜…â˜…â˜…â˜† |

### Audio Models / éŸ³é¢‘æ¨¡å‹

| Type / ç±»å‹ | Model / æ¨¡å‹ | Cost / æˆæœ¬ | Quality / è´¨é‡ | Privacy / éšç§ |
|------------|-------------|------------|---------------|---------------|
| **ASR** | GLMASR (API) | Pay-per-use / æŒ‰é‡ä»˜è´¹ | â˜…â˜…â˜…â˜…â˜… | Cloud / äº‘ç«¯ |
| **ASR** | FunASR (Local) | Free / å…è´¹ | â˜…â˜…â˜…â˜…â˜† | Local / æœ¬åœ° |
| **TTS** | CogTTS | Pay-per-use / æŒ‰é‡ä»˜è´¹ | â˜…â˜…â˜…â˜…â˜… | Cloud / äº‘ç«¯ |
| **TTS** | EdgeTTS | Free / å…è´¹ | â˜…â˜…â˜…â˜†â˜† | Microsoft / å¾®è½¯ |

---

## Performance Benchmarks / æ€§èƒ½æµ‹è¯•

All tests conducted on 4-core 8GB cloud server / æ‰€æœ‰æµ‹è¯•åœ¨4æ ¸8GBäº‘æœåŠ¡å™¨ä¸Šè¿›è¡Œ

### LLM Performance / è¯­è¨€æ¨¡å‹æ€§èƒ½

Test query / æµ‹è¯•è¯­å¥: "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"

| Model / æ¨¡å‹ | Total Time / æ€»è€—æ—¶ | First Token / é¦–Token | Success Rate / æˆåŠŸç‡ |
|-------------|-------------------|---------------------|---------------------|
| **GLM-45-AirX** | 1.682s | 1.297s | 100% (3/3) |
| **GLM-45-Air** | 1.856s | 1.394s | 100% (3/3) |
| **ChatGLMLLM** | 2.035s | 0.739s | 100% (3/3) |
| **GLM-4-Plus** | 2.134s | 0.585s | 100% (3/3) |

### Vision Model Performance / è§†è§‰æ¨¡å‹æ€§èƒ½

| Model / æ¨¡å‹ | Response Time / å“åº”æ—¶é—´ | Stability / ç¨³å®šæ€§ |
|-------------|------------------------|-------------------|
| **ChatGLMVLLM** | 3.221s | 0.483 |
| **GLM-41V-Thinking** | 6.820s | 0.523 |
| **GLM-45V** | 6.923s | 0.343 |

### ASR Performance / è¯­éŸ³è¯†åˆ«æ€§èƒ½

| Model / æ¨¡å‹ | Average Time / å¹³å‡è€—æ—¶ | Type / ç±»å‹ |
|-------------|----------------------|------------|
| **SherpaASR** | 2.867s | Local / æœ¬åœ° |
| **FunASR** | 3.058s | Local / æœ¬åœ° |
| **GLMASR** | 4.374s | API / äº‘ç«¯ |

---

## AutoGLM Integration / AutoGLMé›†æˆ

### Overview / æ¦‚è¿°

AutoGLM transforms Xiaozhi from a simple voice assistant into an intelligent agent capable of controlling your devices through natural language commands.

AutoGLMå°†å°æ™ºä»ç®€å•çš„è¯­éŸ³åŠ©æ‰‹å‡çº§ä¸ºèƒ½å¤Ÿé€šè¿‡è‡ªç„¶è¯­è¨€æ§åˆ¶è®¾å¤‡çš„æ™ºèƒ½ä»£ç†ã€‚

### How It Works / å·¥ä½œåŸç†

```mermaid
graph TD
    A[User Voice Command<br/>ç”¨æˆ·è¯­éŸ³æŒ‡ä»¤] --> B{LLM Intent Recognition<br/>æ„å›¾è¯†åˆ«}
    B -->|Detected Control Intent<br/>è¯†åˆ«åˆ°æ§åˆ¶æ„å›¾| C[Call autoglm_control Function<br/>è°ƒç”¨æ§åˆ¶å‡½æ•°]
    C -->|Send Task Description<br/>å‘é€ä»»åŠ¡æè¿°| D[MCP Client<br/>MCPå®¢æˆ·ç«¯]
    D -->|HTTP POST Request<br/>HTTPè¯·æ±‚| E[AutoGLM Agent Server<br/>AutoGLMæœåŠ¡å™¨]
    E --> F[Execute Automation<br/>æ‰§è¡Œè‡ªåŠ¨åŒ–ä»»åŠ¡]
    F --> G[Return Status<br/>è¿”å›çŠ¶æ€]
    G --> H[Generate Response<br/>ç”Ÿæˆå“åº”]
    H --> I[TTS & Playback<br/>è¯­éŸ³åˆæˆå¹¶æ’­æ”¾]
```

### Example Commands / ç¤ºä¾‹å‘½ä»¤

- "æ‰“å¼€ç½‘æ˜“äº‘éŸ³ä¹" / "Open NetEase Music"
- "å¸®æˆ‘æ‰“å¼€å¾®ä¿¡å¹¶å‘é€æ¶ˆæ¯" / "Open WeChat and send a message"
- "æŸ¥çœ‹ä»Šå¤©çš„æ—¥ç¨‹å®‰æ’" / "Check today's schedule"
- "è®¾ç½®æ˜å¤©æ—©ä¸Š8ç‚¹çš„é—¹é’Ÿ" / "Set an alarm for 8 AM tomorrow"

### Configuration / é…ç½®

The core control logic is implemented in `plugins_func/functions/autoglm_control.py`:

```python
@register_function
async def autoglm_control(task_description: str, action: str = "start_task"):
    """
    Control devices through AutoGLM
    é€šè¿‡AutoGLMæ§åˆ¶è®¾å¤‡
    """
    # Implementation details...
```

---

## Configuration / é…ç½®

### ESP32 Device Configuration / ESP32è®¾å¤‡é…ç½®

#### Method 1: OTA Web Configuration / æ–¹æ³•1ï¼šOTAç½‘é¡µé…ç½®

1. Access / è®¿é—®: `http://YOUR_IP:8003/xiaozhi/ota/`
2. Enter WebSocket address / è¾“å…¥WebSocketåœ°å€
3. Save configuration / ä¿å­˜é…ç½®

#### Method 2: ESP-IDF Configuration / æ–¹æ³•2ï¼šESP-IDFé…ç½®

```bash
# Configure via menuconfig / é€šè¿‡menuconfigé…ç½®
idf.py menuconfig

# Build and flash / ç¼–è¯‘å¹¶çƒ§å½•
idf.py build
idf.py flash

# Monitor output / ç›‘æ§è¾“å‡º
idf.py monitor
```

### Server Configuration / æœåŠ¡å™¨é…ç½®

Main configuration file structure / ä¸»é…ç½®æ–‡ä»¶ç»“æ„:

```yaml
# config.yaml
selected_module:
  llm_module_name: "ChatGLMLLM"  # LLM provider
  asr_module_name: "GLMASR"      # ASR provider
  tts_module_name: "CogTTS"      # TTS provider
  vllm_module_name: "ChatGLMVLLM" # Vision provider

# Model-specific configurations
LLM:
  ChatGLMLLM:
    model_name: "glm-4-flash"
    api_key: ""  # Set in data/.config.yaml
    temperature: 0.7
    max_tokens: 2048

# System settings
GENERAL:
  vad_threshold: 0.5
  audio_format: "pcm"
  sample_rate: 16000
```

---

## Troubleshooting / æ•…éšœæ’é™¤

### Common Issues / å¸¸è§é—®é¢˜

#### 1. WebSocket Connection Failed / WebSocketè¿æ¥å¤±è´¥

**Symptoms / ç—‡çŠ¶:**
- ESP32 cannot connect to server / ESP32æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨
- Connection timeout errors / è¿æ¥è¶…æ—¶é”™è¯¯

**Solutions / è§£å†³æ–¹æ¡ˆ:**
```bash
# Check firewall settings / æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
sudo firewall-cmd --add-port=8000/tcp --permanent
sudo firewall-cmd --add-port=8003/tcp --permanent
sudo firewall-cmd --reload

# Verify server is running / éªŒè¯æœåŠ¡å™¨è¿è¡ŒçŠ¶æ€
netstat -antp | grep python
```

#### 2. GLM-4-Voice Issues / GLM-4-Voiceé—®é¢˜

**Known Issue / å·²çŸ¥é—®é¢˜:**
- API may return errors in certain conditions
- APIåœ¨ç‰¹å®šæ¡ä»¶ä¸‹å¯èƒ½è¿”å›é”™è¯¯

**Temporary Solution / ä¸´æ—¶æ–¹æ¡ˆ:**
- Use CogTTS as primary TTS provider
- ä½¿ç”¨CogTTSä½œä¸ºä¸»è¦TTSæä¾›è€…

#### 3. High Latency / é«˜å»¶è¿Ÿ

**Optimization Steps / ä¼˜åŒ–æ­¥éª¤:**
1. Switch to faster models (Flash series) / åˆ‡æ¢åˆ°æ›´å¿«çš„æ¨¡å‹ï¼ˆFlashç³»åˆ—ï¼‰
2. Enable local ASR if possible / å¦‚å¯èƒ½å¯ç”¨æœ¬åœ°ASR
3. Check network connectivity / æ£€æŸ¥ç½‘ç»œè¿æ¥
4. Monitor server resources / ç›‘æ§æœåŠ¡å™¨èµ„æº

### Logging and Debugging / æ—¥å¿—å’Œè°ƒè¯•

```bash
# View real-time logs / æŸ¥çœ‹å®æ—¶æ—¥å¿—
tail -f xiaozhi.log

# Check error logs / æ£€æŸ¥é”™è¯¯æ—¥å¿—
grep ERROR xiaozhi.log

# Monitor system resources / ç›‘æ§ç³»ç»Ÿèµ„æº
htop

# Check Python processes / æ£€æŸ¥Pythonè¿›ç¨‹
ps aux | grep python
```

---

## Advanced Features / é«˜çº§åŠŸèƒ½

### Custom Personas / è‡ªå®šä¹‰è§’è‰²

The project includes "å°å¹³è€å¸ˆ" (Teacher Xiaoping), an AI assistant persona specialized in:
- Technical explanations / æŠ€æœ¯è®²è§£
- Programming guidance / ç¼–ç¨‹æŒ‡å¯¼
- Project consulting / é¡¹ç›®å’¨è¯¢

Configure custom personas in `config.yaml`:

```yaml
prompt:
  system_prompt: |
    ä½ æ˜¯å°å¹³è€å¸ˆï¼Œä¸€ä½ç²¾é€šæ™ºè°±AIå…¨æ ˆæŠ€æœ¯çš„ä¸“å®¶...
    You are Teacher Xiaoping, an expert in Zhipu AI technologies...
```

### Music Control / éŸ³ä¹æ§åˆ¶

- **Local Music / æœ¬åœ°éŸ³ä¹**: Place `.mp3` files in the `music` folder
- **Online Music / åœ¨çº¿éŸ³ä¹**: Control music apps via AutoGLM
- **Voice Commands / è¯­éŸ³å‘½ä»¤**: "æ’­æ”¾éŸ³ä¹" / "Play music"

### Memory System / è®°å¿†ç³»ç»Ÿ

- **Short-term Memory / çŸ­æœŸè®°å¿†**: Current conversation context
- **Long-term Memory / é•¿æœŸè®°å¿†** (Planned): User preferences and habits

---

## Development / å¼€å‘

### Provider Architecture / Provideræ¶æ„

The system uses a modular Provider pattern for easy extension:

```python
# Example: Custom LLM Provider
class CustomLLMProvider(BaseLLMProvider):
    async def response(self, prompt: str):
        # Implementation
        pass
    
    async def response_with_functions(self, prompt: str, functions: list):
        # Implementation with function calling
        pass
```

### Adding New Models / æ·»åŠ æ–°æ¨¡å‹

1. Create provider class in appropriate directory / åœ¨ç›¸åº”ç›®å½•åˆ›å»ºProviderç±»
2. Implement required interfaces / å®ç°å¿…è¦æ¥å£
3. Register in configuration / åœ¨é…ç½®ä¸­æ³¨å†Œ
4. Update selected modules / æ›´æ–°é€‰æ‹©çš„æ¨¡å—

---

## API Pricing Reference / APIä»·æ ¼å‚è€ƒ

| Service / æœåŠ¡ | Model / æ¨¡å‹ | Pricing / ä»·æ ¼ |
|---------------|-------------|---------------|
| **LLM** | GLM-4-Flash | Â¥0.0001/1K tokens |
| **LLM** | GLM-4.5-Air | Â¥0.001/1K tokens |
| **LLM** | GLM-4-Plus | Â¥0.05/1K tokens |
| **ASR** | GLM-ASR | Â¥0.06/minute |
| **TTS** | CogTTS | Â¥80/1M tokens |
| **Vision** | GLM-4V-Flash | Â¥0.002/1K tokens |

---

## Contributing / è´¡çŒ®

We welcome contributions! Please:

1. Fork the repository / Forkä»“åº“
2. Create a feature branch / åˆ›å»ºç‰¹æ€§åˆ†æ”¯
3. Commit your changes / æäº¤æ›´æ”¹
4. Push to the branch / æ¨é€åˆ°åˆ†æ”¯
5. Create a Pull Request / åˆ›å»ºPull Request

### Development Guidelines / å¼€å‘æŒ‡å—

- Follow PEP 8 style guide / éµå¾ªPEP 8é£æ ¼æŒ‡å—
- Add tests for new features / ä¸ºæ–°åŠŸèƒ½æ·»åŠ æµ‹è¯•
- Update documentation / æ›´æ–°æ–‡æ¡£
- Maintain backward compatibility / ä¿æŒå‘åå…¼å®¹

---

## License / å¼€æºåè®®

This project is based on the original project's open-source license. We thank [@78](https://github.com/78) for the original contribution.

æœ¬é¡¹ç›®åŸºäºåŸé¡¹ç›®çš„å¼€æºåè®®ï¼Œæ„Ÿè°¢è™¾å“¥çš„å¼€æºè´¡çŒ®ã€‚

---

## Acknowledgments / è‡´è°¢

- **[@78 (è™¾å“¥)](https://github.com/78)** - Original Xiaozhi AI Voice Assistant creator / å°æ™ºAIè¯­éŸ³åŠ©æ‰‹åŸä½œè€…
- **[Zhipu AI / æ™ºè°±AI](https://www.zhipuai.cn/)** - Powerful AI model support / å¼ºå¤§çš„AIæ¨¡å‹æ”¯æŒ
- **All contributors and users / æ‰€æœ‰è´¡çŒ®è€…å’Œä½¿ç”¨è€…**

---

## Resources / ç›¸å…³èµ„æº

- [Original Project / åŸé¡¹ç›®](https://github.com/78/xiaozhi-esp32)
- [Server Repository / æœåŠ¡å™¨ç«¯](https://github.com/78/xiaozhi-esp32-server)
- [Zhipu AI Documentation / æ™ºè°±AIæ–‡æ¡£](https://open.bigmodel.cn/dev/api)
- [ESP32 Documentation / ESP32æ–‡æ¡£](https://docs.espressif.com/projects/esp-idf/zh_CN/latest/esp32/)
- [Hardware Tutorial / ç¡¬ä»¶åˆ¶ä½œæ•™ç¨‹](https://github.com/78/xiaozhi-esp32)

---

## Contact & Support / è”ç³»ä¸æ”¯æŒ

- **Issues**: Please submit issues on [GitHub Issues](https://github.com/YOUR_USERNAME/GLM-Xiaozhi/issues)
- **Discussions**: Join our community discussions
- **Email**: your-email@example.com

---

<div align="center">

**âš ï¸ Note / æ³¨æ„**

This project is for learning and research purposes only.

æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ã€‚

---

Made with â¤ï¸ by the Xiaozhi Community

</div>
